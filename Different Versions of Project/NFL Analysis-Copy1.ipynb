{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af4818e9",
   "metadata": {},
   "source": [
    "[Link to website](https://joshmccoy2.github.io)\n",
    "\n",
    "[Link to Powerpoint Overview](https://docs.google.com/presentation/d/e/2PACX-1vQ_JSWNjp1Q82XzXVz54sCTkPGuX-eHlkN1k9STEZX0tWyOPBLRryWuBhE0HTJFHqCm2_9lSVtTaoEj/pub?start=false&loop=false&delayms=3000)\n",
    "\n",
    "\n",
    "<h1><center>Analysis for NFL Teams Current Success Based on Essential Positions Historical Statistics</center></h1>\n",
    "\n",
    "<h1><center>Josh McCoy and Zach Goodman</center></h1>\n",
    "\n",
    "\n",
    "<center>1. Introduction<center>\n",
    "<center>2. Data: Extraction, Transform, and Load<center>\n",
    "<center>3. Exploratory Data Analysis<center>\n",
    "<center>4. Modeling & Evaluation of Models<center>\n",
    "<center>5. Conclusion<center>\n",
    "<center>6. Lessons Learned<center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2235c1",
   "metadata": {},
   "source": [
    " <center>“The dictionary is the only place that success comes before work.” — Vince Lombardi<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc1f144",
   "metadata": {},
   "source": [
    "<h1><center>1. Introduction</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaeb99f1",
   "metadata": {},
   "source": [
    "# Project Goals\n",
    "\n",
    "The goal of our project is to analyze significant positions of NFL teams and see which statistics for those positions predict success. We determined which positions in the NFL are important by utilizing salary cap data for each NFL team between 2014-2020. After we’ve identified the most significant positions for NFL teams, we created a predictive model that examines the statistics for those given positions and predicts the total wins an NFL franchise should have in that given season. Ultimately, we are trying to predict a NFL team’s success in a given season with a limited number of positions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869885d1",
   "metadata": {},
   "source": [
    "# Questions We Are Investigating\n",
    "\n",
    "Which positions do NFL teams pay the most?\n",
    "\n",
    "Is there a difference between good, average, and bad teams in terms of positions they pay the most? \n",
    "\n",
    "Which positions matter the most to predict overall wins for an NFL team?\n",
    "\n",
    "Can we predict an NFL franchise’s wins based on their highest paid players at significant positions?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ff48a7",
   "metadata": {},
   "source": [
    "# Overview of Process\n",
    "### Step 1\n",
    "The first step of our project was to locate CSV files that contained proper data for all NFL teams. We were looking for scores of games, salary information, team information, and player information. After finding the CSV files, we read them in, transformed them into DataFrames, and cleaned them up.\n",
    "### Step 2\n",
    "Once the DataFrames were ready to analyze, we wanted to identify significant positions. We decided to define significance based on how well paid a certain position was for any given season. First, we looked from a league level and found the average highest paid positions in terms of salary cap percentage. We were curious if there was a difference in terms of what positions good, average, and bad teams pay. So, we created parameters for good, average, and bad. Then we organized each team for each season for those categories and took their respective top 5 highest paid positions and added them to a counter. At the end of all of this we identified 8 significant positions.\n",
    "### Step 3\n",
    "Now that all significant positions were identified, we needed statistics for each player. Surprisingly, we could not find a CSV that had all the stats we wanted. Therefore, we decided to web scrape the data from profootballreference, and create a DataFrame for it. This web scraped DataFrame needed a lot of cleaning up. Once clean, we merged it with the salary cap info to create a bigger DataFrame we will use for our model. We noticed later that offensive line stats for LT and G were not on this website, so we bit the bullet and subscribed to ProFootballFocus (PFF) and downloaded CSVs for those two positions.\n",
    "### Step 4\n",
    "Finally, we made it to the model. The first model was a set of models that predicts wins for a player at a significant position. Our team decided it was best to use a linear regression model. We created 7 different models for the 7 significant positions. Once we had the results of all the models, we grabbed the highest paid player from each team for each position in terms of salary cap percentage and put his predicted wins into a DataFrame. This DataFrame is used for our final model.\n",
    "### Step 5\n",
    "The last step was to build another model on the set of models. This model predicts the expected number of wins an NFL Franchise should have based on the number of wins that our previous models predicted for each significant position.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8580fea",
   "metadata": {},
   "source": [
    "<h1><center>2. Data: Extraction, Transform, and Load<h1><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4457dc41",
   "metadata": {},
   "source": [
    "### Importing all libraries and reading in all CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacc730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import re \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "stadiums_df = pd.read_csv(\"CSVs/stadiums.csv\", encoding=\"ISO-8859-1\") #import Stadium info\n",
    "teams_df = pd.read_csv(\"CSVs/nfl_teams.csv\", encoding=\"ISO-8859-1\")  #import Team info\n",
    "scores_df = pd.read_csv(\"CSVs/spreadspoke_scores.csv\", encoding=\"ISO-8859-1\") #import each game score/spread info\n",
    "salary_cap = pd.read_csv(\"CSVs/2014-thru-2020-cap-tables-1.csv\", encoding=\"ISO-8859-1\")\n",
    "stats_tackles = pd.read_csv(\"CSVs/2014-2020T.csv\", encoding=\"ISO-8859-1\",on_bad_lines='skip') #import stats for tackle position\n",
    "stats_guards =  pd.read_csv(\"CSVs/2014-2020G.csv\", encoding=\"ISO-8859-1\",on_bad_lines='skip')  #import stats for guard position\n",
    "missing = pd.read_csv(\"CSVs/Missing Positions for top 8.csv\", encoding=\"ISO-8859-1\")#import custom CSV made to correct issues in salary_cap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef2de1a",
   "metadata": {},
   "source": [
    "## NFL Teams and Scores Dataset\n",
    "\n",
    "We obtained this data from the \"NFL Scores and Betting Data\" dataset found on Kaggle.com. It contains NFL game results since 1966, and information about the betting odds of each game since 1979, along with information about the weather from each game. The betting odds include the favored team, the over/under of each game, and where the game was played. It also contains information about each stadium and team that has ever existed in the NFL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dedfbfa",
   "metadata": {},
   "source": [
    "#### Table 1:\n",
    "\n",
    "This first table comes from \"stadiums.csv\", found in the \"NFL Scores and Betting Data\" dataset. It contains information about all the stadiums that NFL games have been played in and ample information about each of them. For example, it has the stadium location, both in terms of city and coordinates, the opening and/or closing year of the arena, stadium type, weather type, capacity, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3ed06d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stadiums_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ad9707",
   "metadata": {},
   "source": [
    "Lets check the dtypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8febcaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "stadiums_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754bbd1f",
   "metadata": {},
   "source": [
    "Checking the dtypes we see that they are properly formatted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1aefc0",
   "metadata": {},
   "source": [
    "##### Table 2:\n",
    "\n",
    "This table comes from \"nfl_teams.csv\", also found in the \"NFL Scores and Betting Data\" dataset. It contains information about every team that is currently in the league, or has ever been in the NFL. As you can see, it contains the full and short team names, team IDs, and the teams' conference and division, both before and after 2002."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74015a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "teams_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed86d793",
   "metadata": {},
   "source": [
    "#### Table 3:\n",
    "\n",
    "This table comes from \"spreadspoke_scores.csv\", also found in \"NFL Scores and Betting Data\" dataset. It contains information about the scores of each game since the inception of the NFL. Since we only care about modern football, we will limit it to 2014. This data will help us answer questions like \"Which team has had the most success since 2014?\" \"Which teams have the best/worst record each year?\". We will be combining this data with other datasets like salary cap information and position statistics to get a better understanding on what makes NFL teams successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25afa3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c465a98",
   "metadata": {},
   "source": [
    "Now, we are separating regular season games from playoff games. Our intended use of this data is to predict regular season wins. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d1292b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = scores_df[scores_df[\"schedule_season\"]>=2014]  #limiting the DataFrame to dates 2014 and later\n",
    "scores_df = scores_df[scores_df[\"schedule_playoff\"]==False]\n",
    "df_scores = pd.read_csv(\"CSVs/spreadspoke_scores.csv\", encoding=\"ISO-8859-1\") #import each game score/spread info\n",
    "playoffs = df_scores[df_scores[\"schedule_season\"]>=2014]  #limiting the DataFrame to dates 2014 and later\n",
    "playoffs = playoffs[playoffs[\"schedule_playoff\"]==True]\n",
    "scores_df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d054994d",
   "metadata": {},
   "source": [
    "Now, we create a column to add in away and home wins, as well as away and home losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5f8297",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores_df['away_win'] = np.where(scores_df['score_home'] < scores_df['score_away'], 1, 0)\n",
    "scores_df['away_loss'] = np.where(scores_df['score_home'] > scores_df['score_away'], 1, 0)\n",
    "scores_df['home_win'] = np.where(scores_df['score_home'] > scores_df['score_away'], 1, 0)\n",
    "scores_df['home_loss'] = np.where(scores_df['score_home'] < scores_df['score_away'], 1, 0)\n",
    "scores_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c4a5ca",
   "metadata": {},
   "source": [
    "Now, we want to sum all these wins and losses to create a table to see the total success of these teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c6882e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "record = pd.DataFrame()\n",
    "record[\"home_win\"] = scores_df.groupby(\"team_home\")[[\"home_win\"]].sum() \n",
    "record[\"home_loss\"] = scores_df.groupby(\"team_home\")[[\"home_loss\"]].sum() \n",
    "record[\"away_win\"] = scores_df.groupby(\"team_away\")[[\"away_win\"]].sum()\n",
    "record[\"away_loss\"] = scores_df.groupby(\"team_away\")[[\"away_loss\"]].sum()\n",
    "record[\"total_win\"] = record[\"home_win\"] + record[\"away_win\"] \n",
    "record[\"total_loss\"] = record[\"home_loss\"] + record[\"away_loss\"]\n",
    "record = record.reset_index()\n",
    "record = record.rename(columns={'team_home': 'team_name'})\n",
    "record.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e6d213",
   "metadata": {},
   "source": [
    "Finally, we will add this table (record) to our original team table (team_name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3921a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_df = teams_df.merge(record, on=[\"team_name\"], how='inner', suffixes=(False, False))\n",
    "teams_df = teams_df.set_index(\"team_name\")\n",
    "teams_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b65ba24",
   "metadata": {},
   "source": [
    "Now, we will check the dtype. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ea9db0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "teams_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff475aa",
   "metadata": {},
   "source": [
    "## NFL Salary Cap Info Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379b0e8e",
   "metadata": {},
   "source": [
    "#### Table 4:\n",
    "\n",
    "salary_cap was found in the NFL Salaries dataset on Kaggle.com and identifies the cap space information for each team like player name, position, cap hit, cap percentage, season, and team. Salary Cap limits NFL franchises in the amount of money they spend on their respective players. This is important because we want to analyze if there is a difference in the positions taking up the most cap percentage for unsuccessful teams versus successful teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8a3c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_cap = salary_cap.sort_values(by=[\"team\", \"season\", \"pos\"], ascending=True)\n",
    "salary_cap = salary_cap.rename(columns={\"name\":\"Player\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5626c7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_cap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0fc2c8",
   "metadata": {},
   "source": [
    "#### Table 5:\n",
    "\n",
    "Later in the project, we found there were some teams with 0 players at a given position we were examining. This was because a player, for example, would be considered a right tackle (RT) or a tackle (T), instead of a left tackle (LT). To try to solve this issue, we manually checked on those players, and created a new CSV that we'd turn into a DataFrame, with the hopes of using this data to correct some issues in salary_cap. This DataFrame was titled 'missing'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1750c075",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = missing.rename(columns={\"ï»¿Team\":\"team\", \"Fix Player Name\":\"Player\", \"Missing Position \":\"pos\", \"Season\":\"season\"})\n",
    "missing.head(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c4ce25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix the Trent Brown issue\n",
    "for i in range(len(salary_cap)):\n",
    "    if salary_cap.iloc[i][\"Player\"] == \"Trenton Brown\":\n",
    "        salary_cap.at[salary_cap.index[i], \"Player\"] = \"Trent Brown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5efc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_players_df = []\n",
    "#Fixing Missing Players\n",
    "for i in range(len(missing)):\n",
    "    name = missing.loc[i][\"Player\"]\n",
    "    team = missing.loc[i][\"team\"]\n",
    "    season = missing.loc[i][\"season\"]\n",
    "    \n",
    "    idx = salary_cap[(salary_cap.Player == name) & (salary_cap.season == season)].index.values.astype(int)\n",
    "    sal_cap_obs = salary_cap.loc[idx]\n",
    "    \n",
    "    \n",
    "    #If player doesn't exist in salary_cap:\n",
    "    if (idx.size == 0):\n",
    "        \n",
    "        new = salary_cap[(salary_cap.Player == name) & (salary_cap.season == (season-1))]\n",
    "        missing_player = pd.DataFrame(new)\n",
    "        missing_player[\"season\"] = (season)\n",
    "        missing_player[\"team\"] = (team)\n",
    "        missing_players_df.append(missing_player)\n",
    "\n",
    "        \n",
    "        if new.index.size == 0:\n",
    "        \n",
    "            new = salary_cap[(salary_cap.Player == name) & (salary_cap.season == (season+1))]\n",
    "            missing_player = pd.DataFrame(new)\n",
    "            missing_player[\"season\"] = (season)\n",
    "            missing_player[\"team\"] = (team)\n",
    "            missing_players_df.append(missing_player)\n",
    "\n",
    "missing_df = pd.concat(missing_players_df)\n",
    "missing_df\n",
    "capLen = len(salary_cap)\n",
    "\n",
    "missing_df.reset_index(inplace=True)\n",
    "x = missing_df.index\n",
    "missing_df = missing_df.set_index(x+capLen)\n",
    "missing_df\n",
    "\n",
    "salary_cap = pd.concat([salary_cap, missing_df], ignore_index = True)\n",
    "salary_cap = salary_cap.drop(columns=[\"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f18a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixing positions when should be LT instead of T/RT\n",
    "for i in range(len(missing)):\n",
    "    name = missing.loc[i][\"Player\"]\n",
    "    team = missing.loc[i][\"team\"]\n",
    "    season = missing.loc[i][\"season\"]\n",
    "    pos = missing.loc[i][\"pos\"]\n",
    "    \n",
    "    idx = salary_cap[(salary_cap.Player == name) & (salary_cap.season == season)].index.values.astype(int)\n",
    "    idx = idx[0]\n",
    "    sal_cap_obs = salary_cap.loc[idx]\n",
    "\n",
    "    salary_cap.at[salary_cap.index[idx], 'pos'] = pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722eb466",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_cap[salary_cap[\"team\"]==\"Green Bay Packers \"]\n",
    "#Fixed an issue where \"Green Bay Packers\" was actually \"Green Bay Packers \"\n",
    "salary_cap['team'] = salary_cap['team'].str.replace('Green Bay Packers ','Green Bay Packers')\n",
    "salary_cap.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a50466",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_cap.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ab6966",
   "metadata": {},
   "source": [
    "The dtypes for each are correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49529751",
   "metadata": {},
   "source": [
    "## PFF Stats Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a4d35b",
   "metadata": {},
   "source": [
    "#### Table 6\n",
    "\n",
    "This table comes from ProFootballFocus (PFF) and focuses on statistics for the left tackle (LT) position. It contains information such as player, season, team, games played, sacks allowed, pressures allowed, QB hits allowed, number of pass blocking plays, and number of run blocking plays. These stats will be used in our predictive model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346c61c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_tackles.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fa929e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_tackles.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7374ea10",
   "metadata": {},
   "source": [
    "All dtypes are properly formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a25fbc",
   "metadata": {},
   "source": [
    "#### Table 7\n",
    "\n",
    "This table comes from ProFootballFocus (PFF) and focuses on statistics for the guard position. Exactly like table 5, it contains information such as player, season, team, games played, sacks allowed, pressures allowed, QB hits allowed, number of pass blocking plays, and number of run blocking plays. These stats will be used in our predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce92ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_guards.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a24c65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_guards.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c83fd1",
   "metadata": {},
   "source": [
    "Dtypes are good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2eba463",
   "metadata": {},
   "source": [
    "<h1><center>3. Exploratory Data Analysis<h1><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8509757",
   "metadata": {},
   "source": [
    "#### Step 1\n",
    "\n",
    "First, we want to display the total wins by each NFL franchise in each season. We are using each team's seasonal record to create visualizations, to distinguish what makes teams 'good, average, or bad', and to determine the frequency of positions on these types of teams. Additionally, we will use seasonal win values to create our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63045fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonRecord = pd.DataFrame()\n",
    "seasonRecord[\"Season\"] = scores_df[\"schedule_season\"]\n",
    "seasonRecord[\"Home Team\"] = scores_df[\"team_home\"]\n",
    "seasonRecord[\"Away Team\"] = scores_df[\"team_away\"]\n",
    "seasonRecord[\"home_win\"] = scores_df[\"home_win\"]\n",
    "seasonRecord[\"away_win\"] = scores_df[\"away_win\"]\n",
    "seasonRecord[\"away_loss\"] = scores_df[\"away_loss\"]\n",
    "seasonRecord[\"home_loss\"] = scores_df[\"home_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b9de74",
   "metadata": {},
   "outputs": [],
   "source": [
    "hometeam_wins = seasonRecord.groupby([\"Home Team\",\"Season\"])[[\"home_win\"]].sum() \n",
    "hometeam_loss = seasonRecord.groupby([\"Home Team\",\"Season\"])[[\"home_loss\"]].sum() \n",
    "awayteam_loss = seasonRecord.groupby([\"Away Team\",\"Season\"])[[\"away_loss\"]].sum() \n",
    "awayteam_wins = seasonRecord.groupby([\"Away Team\",\"Season\"])[[\"away_win\"]].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bab8175",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_names = [hometeam_wins, hometeam_loss, awayteam_wins, awayteam_loss]\n",
    "piv_names = [\"homeTeamWinsPivot\", \"homeTeamLossPivot\", \"awayTeamWinsPivot\", \"awayTeamLossPivot\"]\n",
    "dfs = [\"homeWin\", \"homeLoss\", \"awayWin\", \"awayLoss\"]\n",
    "colNames = [\"home_win\", \"home_loss\", \"away_win\", \"away_loss\"]\n",
    "indexNames = [\"Home Team\", \"Home Team\", \"Away Team\", \"Away Team\"]  \n",
    "\n",
    "for i in range(len(groupby_names)):\n",
    "    globals()[piv_names[i]] = pd.pivot_table(groupby_names[i], values=colNames[i], index=indexNames[i], columns=\"Season\")\n",
    "    globals()[dfs[i]] = globals()[piv_names[i]].reset_index()\n",
    "    globals()[dfs[i]] = globals()[dfs[i]].rename(columns={indexNames[i]:\"Team\"})\n",
    "    globals()[dfs[i]] = globals()[dfs[i]].set_index([\"Team\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270787e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a Dataframe with just wins: seasonWins\n",
    "seasonWins = pd.DataFrame()\n",
    "#Creating a Dataframe with just losses: seasonLosses\n",
    "seasonLoss = pd.DataFrame()\n",
    "season_yrs = [2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022]\n",
    "for year in range(len(season_yrs)):\n",
    "    stringW = str(season_yrs[year]) + \" W\"\n",
    "    stringL = str(season_yrs[year]) + \" L\"\n",
    "    seasonWins[stringW] = homeWin[season_yrs[year]] + awayWin[season_yrs[year]]\n",
    "    seasonLoss[stringL] = homeLoss[season_yrs[year]] + awayLoss[season_yrs[year]]\n",
    "    year += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db12b7d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Creating a Dataframe with both wins and losses\n",
    "year_rec = pd.DataFrame()\n",
    "year_rec = seasonWins.merge(seasonLoss, on=[\"Team\"])\n",
    "insert_num = 1\n",
    "for year in range(len(season_yrs)):\n",
    "    stringL = str(season_yrs[year]) + \" L\"\n",
    "    column_to_move = year_rec.pop(stringL)\n",
    "    year_rec.insert(insert_num, stringL, column_to_move)\n",
    "    insert_num += 2\n",
    "year_rec.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7192f9",
   "metadata": {},
   "source": [
    "We want to graph each team's amount of wins for each season from 2014-2020. Because there are 32 teams and reading 32 lines on one graph is hard to follow, we will do this by breaking the teams apart based on their respective divisions: NFC East, NFC South, AFC East, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277cfa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonWins_to2020 = pd.DataFrame(seasonWins)\n",
    "seasonWins_to2020 = seasonWins_to2020.drop(columns=[\"2021 W\", \"2022 W\"])\n",
    "seasonWins_to2020 = seasonWins_to2020.drop(index=\"Washington Commanders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad790dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_rec = pd.DataFrame()\n",
    "year_rec = seasonWins.merge(seasonLoss, on=[\"Team\"])\n",
    "insert_num = 1\n",
    "for year in range(len(season_yrs)):\n",
    "   stringL = str(season_yrs[year]) + \" L\"\n",
    "   column_to_move = year_rec.pop(stringL)\n",
    "   year_rec.insert(insert_num, stringL, column_to_move)\n",
    "   insert_num += 2\n",
    "year_rec.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b3a219",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 14\n",
    "for i in range(20-13):\n",
    "    x = \"cap\" + str(num) \n",
    "    globals()[x] = pd.DataFrame(salary_cap)\n",
    "    fullYr = int(str(20) + str(num))\n",
    "    globals()[x] = globals()[x][globals()[x][\"season\"]==fullYr]\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa9b327",
   "metadata": {},
   "outputs": [],
   "source": [
    "yrNum = 14\n",
    "caps = [cap14[\"team\"], cap15[\"team\"], cap16[\"team\"], cap17[\"team\"], cap18[\"team\"], cap19[\"team\"], cap20[\"team\"]]\n",
    "for i in range(20-13):\n",
    "    bigTeam = \"big_team_list\" + str(yrNum)\n",
    "    tmLst = \"team_list\" + str(yrNum)\n",
    "    globals()[tmLst] = []\n",
    "    \n",
    "    globals()[bigTeam] = caps[i]\n",
    "    globals()[bigTeam] = globals()[bigTeam].values.tolist()\n",
    "    \n",
    "    [globals()[tmLst].append(x) for x in globals()[bigTeam] if x not in globals()[tmLst]]\n",
    "    yrNum += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4bce39",
   "metadata": {},
   "outputs": [],
   "source": [
    "massive_list = salary_cap[\"team\"].values.tolist()\n",
    "full_team_list = []\n",
    "[full_team_list.append(x) for x in massive_list if x not in full_team_list]\n",
    "[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00e9041",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_list = []\n",
    "for i in range(1120):\n",
    "    idx_list.append(i)    \n",
    "top5 = pd.DataFrame(index=idx_list, columns=[\"Player\", \"pos\", \"cap_percent\", \"season\", \"team\"])\n",
    "top5[\"Season Wins\"] = float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046ff6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonWinGraph = pd.DataFrame(seasonWins_to2020)\n",
    "seasonWinGraph = homeTeamWinsPivot + awayTeamWinsPivot\n",
    "seasonWinGraph = seasonWinGraph.rename_axis(index={\"Home Team\": \"Team\"})\n",
    "seasonWinGraph = seasonWinGraph.drop(columns=[2021, 2022])\n",
    "\n",
    "current_teams = pd.DataFrame(teams_df, columns=[\"team_name\", \"team_division\"])\n",
    "current_teams = current_teams.drop(columns=[\"team_name\"])\n",
    "current_teams= current_teams.rename_axis(index={\"team_name\": \"Team\"})\n",
    "\n",
    "current_teams = current_teams.merge(seasonWinGraph, on=[\"Team\"], how='inner', suffixes=(False, False))\n",
    "current_teams = current_teams.drop(columns=[2014, 2015, 2016, 2017, 2018, 2019, 2020])\n",
    "current_teams.loc[\"St. Louis Rams\"][\"team_division\"] == \"NFC West\"\n",
    "current_teams.at[\"St. Louis Rams\", \"team_division\"] = \"NFC West\"\n",
    "current_teams.at[\"Las Vegas Raiders\", \"team_division\"] = \"AFC West\"\n",
    "current_teams = current_teams.drop(index=\"Washington Commanders\")\n",
    "seasonWinGraph = pd.DataFrame.transpose(seasonWinGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a7ae6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "season_years = [2014, 2015, 2016, 2017, 2018, 2019, 2020]\n",
    "nfl_leagues = [\"AFC\", \"NFC\"]\n",
    "divs = [\"North\", \"South\", \"East\", \"West\"]\n",
    "league_divs = []\n",
    "for i in range(len(nfl_leagues)):\n",
    "    league = nfl_leagues[i]\n",
    "    for x in range(len(divs)):\n",
    "        div = divs[x]\n",
    "        strng = league + \" \" + div\n",
    "        league_divs.append(strng)\n",
    "afc = []\n",
    "afc = league_divs[0:4]\n",
    "nfc = []\n",
    "nfc = league_divs[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b1c27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 0\n",
    "fig, ax = plt.subplots(4, 2, figsize=(10,15), layout='constrained')    \n",
    "fig.tight_layout(pad=5.0)\n",
    "fig.subplots_adjust(left = 0.1, top = 0.9, right = 0.9, bottom = 0.1, hspace = 0.5, wspace = 0.5)\n",
    "title = \"AFC Teams' Total Wins Per Season.                                 NFC Teams' Total Wins Per Season.\" + \"\\n\"\n",
    "fig.suptitle(title, fontsize=20)\n",
    "label_loc = 0\n",
    "\n",
    "for var in range(2):\n",
    "    xfc = afc\n",
    "    label_loc = -1\n",
    "    if (var==1):\n",
    "        xfc = nfc\n",
    "        label_loc = +1.25\n",
    "        \n",
    "    for team in range(len(full_team_list)):\n",
    "    \n",
    "        for league in range(len(xfc)):\n",
    "            league = (league%4)\n",
    "        \n",
    "            if (current_teams.loc[full_team_list[team]][\"team_division\"] == xfc[league]) == True:\n",
    "                                   \n",
    "                ax[league][var].set_xlabel('Season')\n",
    "                ax[league][var].set_ylabel('Games Won')\n",
    "\n",
    "                ax[league][var].plot(season_years, seasonWinGraph[full_team_list[team]], label=full_team_list[team])\n",
    "                ax[league][var].legend(loc='upper left', bbox_to_anchor=(label_loc, .5))\n",
    "                \n",
    "    for league in range(len(xfc)):\n",
    "        \n",
    "        ax[league][var].set_title(xfc[league])\n",
    "\n",
    "    var += 1\n",
    "    \n",
    "plt.show(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f8e840",
   "metadata": {},
   "source": [
    "These graphs illustrate each team's success over the years 2014-2020. We decided to separate them by division. Some divisions have five teams because of location changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08696a13",
   "metadata": {},
   "source": [
    "#### Step 2\n",
    "\n",
    "Now that we have each team's wins and losses for each season, we can define what it means to be a good, average, and bad team. We will do this by taking the STD, mean, and analyzing boxplots of wins per team for each season from 2014-2020. This is because our Salary Cap dataset only has data from 2014-2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba299b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonWins_to2020.std().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16569ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonWins_to2020.mean().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171ffbc1",
   "metadata": {},
   "source": [
    "When looking at mean and STD, it shows us that the average amount of wins per season is approximately 8. Let's generalize that 8 wins is the average and any team within one standard deviation is considered average. Therefore, 0-4 wins classify a team as \"Bad\", 5-11 wins classify a team as \"Average\", and 12-16 wins classify a team as \"Good\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bbebc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonWins_to2020.median().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70d1b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot = seasonWins_to2020.boxplot(grid=False,vert=False)\n",
    "plt.xlabel('Wins') \n",
    "plt.ylabel('Year') \n",
    "plt.title(\"Box Plots for Each Season's Wins\")\n",
    "plt.show(boxplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd8cdb1",
   "metadata": {},
   "source": [
    "When looking at the median and box plots we see that the median (7.86) is almost exactly our mean (7.97) which indicates that the data is normally distributed. Therefore, we do not have to worry about too many outliers. This outcome further justifies our definitions for good, average, and bad.\n",
    "It is also worth mentioning that the 3rd quartile (75%) is approximately 10 wins on average and the 1st quartile (25%) is approximately 5 wins on average. These results further support our definitions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b11391",
   "metadata": {},
   "source": [
    "#### Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72906e0d",
   "metadata": {},
   "source": [
    "Before we look at the differences in positions paid for good, average, and bad, let’s look at positional value from a league level. In other words, which positions does the NFL at a whole value higher than others? This provides us with a basis going forward. Let’s see how every position takes a bite out of the pie:)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8573a321",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = salary_cap.groupby(\"pos\")[[\"cap_percent\"]].sum()\n",
    "y = y.reset_index()\n",
    "y.groupby(\"pos\")[[\"cap_percent\"]].sum()\n",
    "y.sort_values(\"cap_percent\",ascending=False,inplace=True)\n",
    "\n",
    "mylabels = y[\"pos\"]\n",
    "ys = y[\"cap_percent\"]\n",
    "\n",
    "porcent = 100.*ys/ys.sum()\n",
    "patches, texts = plt.pie(ys, startangle=90, radius=1.2,shadow = True)\n",
    "labels = ['{0} - {1:1.2f} %'.format(i,j) for i,j in zip(mylabels,porcent)]\n",
    "\n",
    "sort_legend = True\n",
    "if sort_legend:\n",
    "    patches, labels, dummy =  zip(*sorted(zip(patches, labels, ys),\n",
    "                                          key=lambda x: x[2],\n",
    "                                          reverse=True))\n",
    "\n",
    "plt.legend(patches, labels, loc='upper right', bbox_to_anchor=(-0.1, 1.),\n",
    "           fontsize=8)\n",
    "plt.title(\"League Average Salary Cap Percentage Per Position\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0b789a",
   "metadata": {},
   "source": [
    "Throughout the years 2014-2020, there is a large portion of the teams cap percentage going towards QB, WR, CB, DE, OLB, G, and DT. Approximately 64% of any given team’s total cap space is devoted to these 7 positions. We will further investigate this to see if winning franchises pay different positions more frequently than losing franchises."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7292c1",
   "metadata": {},
   "source": [
    "\n",
    "Now, we want to classify these teams into our stated definitions of \"good\", \"average\", and \"bad\". Once they are classified into these groups, we will then use the Salary Cap DataFrame to identify what the top 5 positions for that team were in terms of salary cap percentage. Next, we will count the total number of positions by each group: good, average, and bad, to try to identify if there are differences in the positional valuation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd1303f",
   "metadata": {},
   "outputs": [],
   "source": [
    "number = 2014\n",
    "Win_Values = [16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.0]\n",
    "pos_list = [\"C\", \"CB\", \"DE\", \"DT\", \"FB\", \"FS\", \"G\", \"ILB\", \"K\", \"KR\", \"LB\", \"LS\", \"LT\", \"OLB\", \"P\", \"QB\", \"RB\", \"RT\", \"S\", \"SS\", \"T\", \"TE\", \"WR\"] \n",
    "\n",
    "\n",
    "for i in range(20-13):\n",
    "    var = \"win\" + str(number) \n",
    "    globals()[var] = pd.DataFrame()\n",
    "    globals()[var][\"Win Values\"] = Win_Values\n",
    "    globals()[var] = globals()[var].set_index(\"Win Values\")\n",
    "    \n",
    "        \n",
    "    for position in pos_list:\n",
    "        globals()[var][position] = 0 \n",
    "    \n",
    "    number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc88081",
   "metadata": {},
   "outputs": [],
   "source": [
    "season_years = [2014, 2015, 2016, 2017, 2018, 2019, 2020]\n",
    "season_yrs = [2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022]\n",
    "pos_list = [\"C\", \"CB\", \"DE\", \"DT\", \"FB\", \"FS\", \"G\", \"ILB\", \"K\", \"KR\", \"LB\", \"LS\", \"LT\", \"OLB\", \"P\", \"QB\", \"RB\", \"RT\", \"S\", \"SS\", \"T\", \"TE\", \"WR\"] \n",
    "year = 2014\n",
    "yr = 14\n",
    "x=0\n",
    "for year in range(len(season_years)):\n",
    "    \n",
    "    lst = \"team_list\" + str(yr)\n",
    "    \n",
    "    cap = \"cap\" + str(yr)\n",
    "    \n",
    "    stringW = str(season_yrs[year]) + \" W\"\n",
    "    \n",
    "    df_name = \"win\" + str(season_years[year])\n",
    "    \n",
    "    for team in globals()[lst]:\n",
    "        winScore = year_rec[stringW].loc[team]\n",
    "    \n",
    "        df = globals()[cap][globals()[cap][\"team\"]==team].sort_values(by = [\"cap_percent\"], ascending=False).head(5)\n",
    "\n",
    "\n",
    "        df = df.reset_index()\n",
    "    \n",
    "        for i in range(len(df)):\n",
    "            top5.loc[x] = df.iloc[i]\n",
    "            x = x + 1\n",
    "\n",
    "        for position in pos_list:\n",
    "            for i in range(len(df[\"pos\"])):\n",
    "                if df.loc[i][\"pos\"] == position:\n",
    "                    globals()[df_name].loc[winScore][position] = globals()[df_name].loc[winScore][position] + 1\n",
    "    \n",
    "    year += 1\n",
    "    yr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5e7d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(len(season_years)):\n",
    "    transposed = \"w\" + str(season_years[year])\n",
    "    og = \"win\" + str(season_years[year])   \n",
    "    globals()[transposed] = pd.DataFrame.transpose(globals()[og])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008bae20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All the stats added up from seasons 2014-2020\n",
    "w14to20 = pd.DataFrame()\n",
    "w14to20 = w2014 + w2015 + w2016 + w2017 + w2018 + w2019 + w2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2697848e",
   "metadata": {},
   "outputs": [],
   "source": [
    "good = pd.DataFrame()\n",
    "average = pd.DataFrame()\n",
    "bad = pd.DataFrame()\n",
    "\n",
    "for i in range(5):\n",
    "    score = i + 12.0\n",
    "    iscore = i + 0.0\n",
    "    bad[iscore] = w14to20[iscore]\n",
    "    good[score] = w14to20[score]\n",
    "    \n",
    "for i in range(7):\n",
    "    score = i + 5.0\n",
    "    average[score] = w14to20[score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7667067f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_freq = pd.DataFrame(index=w14to20.index, columns=[\"Good\", \"Average\", \"Bad\"])\n",
    "# pos_freq(columns =[\"Good\", \"Average\", \"Bad\"] = 0\n",
    "\n",
    "levels = [good, average, bad]\n",
    "level_str = [\"Good\", \"Average\", \"Bad\"]\n",
    "\n",
    "for i in range(len(levels)):\n",
    "    pos_freq[level_str[i]] = levels[i].sum(axis=1)\n",
    "\n",
    "#top 5 for Good: QB, LT, WR, OLB, CB\n",
    "#top 5 for Average: QB, DE, WR, CB, OLB\n",
    "#top 5 for Bad: WR, CB, QB, DE, OLB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3b3af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(len(season_years)):\n",
    "    string = str(season_years[year]) + \" W\"\n",
    "    \n",
    "    for team in range(len(full_team_list)):\n",
    "        \n",
    "        for i in range(len(top5)):\n",
    "            \n",
    "            if (top5.loc[i][\"season\"]== season_years[year]):\n",
    "                \n",
    "                if (top5.loc[i][\"team\"]== full_team_list[team]):\n",
    "                    top5.loc[i, \"Season Wins\"] = seasonWins.loc[full_team_list[team]][string]\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e5162b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top5.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ab374b",
   "metadata": {},
   "source": [
    "The above DataFrame, top5, identifies the top 5 highest paid positions for each team in each season. Based on previously defined definitions of good, average, and bad, the positions will be counted respectively for each classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9748af",
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = pos_freq.plot.bar(rot=0, subplots=True, legend=None, sharex=False, title=\"Frequecy of Positions in the Top 5 of Team's Salary Cap Space\")\n",
    "fig.tight_layout(pad=5.0)\n",
    "plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9,wspace=0.4,hspace=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9b3426",
   "metadata": {},
   "source": [
    "Here, we are trying to analyze if there is a difference in what positions good, average, and bad teams pay. These graphs are showing the frequency that a position was in the top 5 for their respective team in terms of market cap percentage. From these graphs, we see that there are a core group of positions that are valued higher than others. These positions are as follows: CB, DE, WR, LT, QB, OLB. Based on these findings, we will only analyze these position's statistics because it is apparent that NFL teams value them higher than others. \n",
    "\n",
    "QB, WR, CB, DE, OLB, G, and DT - these are the top positions from the overall league data. When looking at the separate groups, we notice that the LT position is clearly valued as important also. The rest of the positions seem to be closely in line with the league average. It also is worth mentioning that less of the time good teams pay DT compared to average and bad teams. \n",
    "\n",
    "### Significant Positions:\n",
    "#### Offense: \n",
    "QB, WR, G, LT\n",
    "\n",
    "#### Defense \n",
    "CB, DE, OLB, DT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f3a4aa",
   "metadata": {},
   "source": [
    "When we were creating models for each position, we noticed an issue with OLB and DE. Since we were using data from two different sources, the players were classified into different positions. Some were listed as DE and others as OLB. Therefore, we decided to combine these two positions because they are alike and have a very similar function based on whichever type of defense the team runs (3-4 or 4-3)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50ecfc4",
   "metadata": {},
   "source": [
    "### Updated Significant Positions:\n",
    "#### Offense: \n",
    "QB, WR, G, LT\n",
    "\n",
    "#### Defense \n",
    "CB, DE/OLB, DT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd2d009",
   "metadata": {},
   "source": [
    "#### Step 4\n",
    "\n",
    "We need the 7 highest paid players from each team for each significant position. The code below is completing this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ec775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_cap = salary_cap.copy(deep=True)\n",
    "other_cap['pos'] = other_cap['pos'].replace({\"LB\":\"OLB/DE\", \"ILB\":\"OLB/DE\",\"DE\":\"OLB/DE\"})\n",
    "\n",
    "num = 14\n",
    "for i in range(20-13):\n",
    "    x = \"cap_\" + str(num) \n",
    "    globals()[x] = pd.DataFrame(other_cap)\n",
    "    fullYr = int(str(20) + str(num))\n",
    "    globals()[x] = globals()[x][globals()[x][\"season\"]==fullYr]\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05aae955",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_list = []\n",
    "for i in range(2000):\n",
    "    idx_list.append(i) \n",
    "\n",
    "top7 = pd.DataFrame(index=idx_list, columns=[\"Player\", \"pos\", \"cap_percent\", \"season\", \"team\", \"cap_hit\"])\n",
    "important_pos = [\"QB\", \"WR\", \"G\", \"LT\", \"CB\",\"OLB/DE\", \"DT\"]\n",
    "season_years = [14, 15, 16, 17, 18, 19, 20]\n",
    "\n",
    "yr = 14\n",
    "x=0\n",
    "for year in range(len(season_years)):\n",
    "    \n",
    "    lst = \"team_list\" + str(season_years[year])\n",
    "    \n",
    "    cap = \"cap_\" + str(season_years[year])\n",
    "    \n",
    "    for team in globals()[lst]:\n",
    "        \n",
    "        df = globals()[cap][globals()[cap][\"team\"]==team].sort_values(by = [\"cap_percent\"], ascending=False)\n",
    "        df = df.drop_duplicates(subset=['pos'])\n",
    "        df = df.reset_index()\n",
    "        df = df.drop(columns=[\"index\"])\n",
    "        \n",
    "        for i in range(len(df)):\n",
    "    \n",
    "            for pos in range(len(important_pos)):\n",
    "                test = pd.DataFrame(columns=[\"Player\", \"pos\", \"cap_percent\", \"season\", \"team\", \"cap_hit\"])\n",
    "                \n",
    "                if df['pos'].iloc[i] == important_pos[pos]:\n",
    "                    test.loc[i] = df.iloc[i]\n",
    "                    test = test.dropna()\n",
    "                    \n",
    "                    top7.iloc[x] = test.loc[i]\n",
    "                    x += 1\n",
    "\n",
    "top7 = top7.dropna()\n",
    "top7 = top7.drop(columns=[\"cap_hit\"])\n",
    "top7.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22354eb7",
   "metadata": {},
   "source": [
    "Top7 DataFrame identifies the 7 highest paid players at each significant position, for each team, for each season. As seen above, Top7 is showing the results for the 2014 Arizona Cardinals. This DataFrame is important because we will use this for our overall team wins model (Model 2). Each of these players will have predicted wins, which we will plug in for model 2 to predict the seasonal win value of the whole team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c12a3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonCapWins = top5[['season',\"team\",'Season Wins']].copy()\n",
    "seasonCapWins = seasonCapWins.drop_duplicates()\n",
    "seasonCapWins.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0353752f",
   "metadata": {},
   "source": [
    "We need to add each team's respective wins for that season so we can predict this value in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636a5955",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cap_wins = other_cap.merge(seasonCapWins, on=[\"season\", \"team\",], how='left')\n",
    "cap_wins.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa92736",
   "metadata": {},
   "source": [
    "As previously stated, we want to combine DE and OLB. The code below is accomplishing this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c913e92d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cap_wins['pos'] = cap_wins['pos'].replace(['OLB'], 'OLB/DE')\n",
    "cap_wins['pos'] = cap_wins['pos'].replace(['DE'], 'OLB/DE')\n",
    "cap_wins[cap_wins[\"pos\"]=='OLB/DE'].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4841c630",
   "metadata": {},
   "source": [
    "<h1><center>4. Modeling & Evaluation of Models<h1><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1f9a68",
   "metadata": {},
   "source": [
    "# Our Models\n",
    "\n",
    "For both models, we decided to run a linear regression model. This is because a linear regression model has beta coefficients which learn which stats or positions matter more to the success of the overall model. This is important for our models because there are many different statistics and position groups.\n",
    "\n",
    "#### Model 1\n",
    "\n",
    "We looked at each season from 2014-2020, took seasonal stats for each position, then separated each position's stats into a unique DataFrame. Therefore, there is one DataFrame per significant position. The observations are the individual players and the columns are stats for that given position, including games won in each season - \"Season Wins\".\n",
    "\n",
    "Next, with these DataFrames, we created a predictive model for each position. It predicts the amount of games won in a season for each player based on their seasonal statistics.\n",
    "\n",
    "Independent Variables: Given stats for a certain position. Example: QB stats - passing yards, rushing yards, passing TDs, interceptions, etc.\n",
    "\n",
    "Dependent variable: Wins for a player. Example: Daniel Jones - 7 wins\n",
    "\n",
    "\n",
    "#### Model 2\n",
    "\n",
    "Once we have each team’s significant players' projected wins, we trained another predictive model on the player position models to predict a team’s total wins with these given players.\n",
    "\n",
    "Independent variables: Predicted wins from the models above for each specific position group. Example: QB 10.7 wins, DE 8.3 wins, CB 11.4 wins, etc.\n",
    "\n",
    "Dependent variable: Wins for a team. Example: New York Giants - 14 wins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc00889",
   "metadata": {},
   "source": [
    "# Model 1 and Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a657e5c",
   "metadata": {},
   "source": [
    "## Defense WebScraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9886beaa",
   "metadata": {},
   "source": [
    "#### Scraping to create table 8:\n",
    "\n",
    "Now, we need to scrape each position's statistics for seasons 2014-2020. We found the site \"https://www.pro-football-reference.com/\" that has season stats for each position. It has stats such as, total sacks, QB pressures, passes defended, passing touchdowns, interceptions, etc.\n",
    "\n",
    "We will scrape this data into a DataFrame. It has unnecessary stats such as fumbles recovered for touchdowns and yards gained after an interception. Therefore, we need to do some cleanup work to make it more useful to our overall goal. It also only has abbreviations of team names, so we will need to correct that issue so we can merge this DataFrame with the DataFrame that contains the top 7 significant players.\n",
    "\n",
    "Before that, with the defense DataFrame, we need to map the specific positions to the general positions we will be examining: CB, OLB/DE, and DT. Once this is done, we will build a linear regression model for each position, predicting the number of wins a player will win in a season, given their stats. \n",
    "\n",
    "After this is done, we will merge this with the top7 DataFrame we've made to take the highest paid players of these positions on each team. We will then build our second model with those predicted win values, predicting a team's total win value for a given season with each highest paid position's win prediction.\n",
    "\n",
    "To do this, we must repeat this process for the other positions, then we will be ready to build our second and final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5075b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WEB-SCRAPING FOR LOOP RESPONSIBLE FOR DEFENSIVE POSITIONS\n",
    "\n",
    "years = [2014,2015,2016,2017,2018,2019,2020]\n",
    "df_list = []\n",
    "for y in years:\n",
    "    \n",
    "    url = 'https://www.pro-football-reference.com/years/' + str(y) + '/defense.htm'\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "\n",
    "    b = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(b.content)\n",
    "    table = soup.find(\"table\")\n",
    "    table_df = pd.read_html(str(table))[0]\n",
    "    \n",
    "    table_df = table_df.fillna(value=0)\n",
    "    table_df.columns = table_df.columns.droplevel()\n",
    "    table_df[\"season\"]=y\n",
    "    \n",
    "    table_df = table_df.drop(columns=[\"Yds\", \"TD\", \"Lng\", \"Fmb\", \"Sfty\",\"Rk\"])\n",
    "    table_df = table_df.rename(columns={\"Tm\":\"Team\", \"Pos\":\"pos\", \"G\":\"Played\", \"GS\":\"Started\", \"PD\":\"Pass Def\", \"Sk\":\"Sack\"})\n",
    "    table_df[\"Player\"] = table_df[\"Player\"].apply(lambda x: x.replace(\"*\",\"\").replace(\"+\",\"\")) \n",
    "    \n",
    "     \n",
    "    if (y<=2015):\n",
    "        table_df[\"Team\"] = table_df[\"Team\"].map({\n",
    "    \"HOU\": \"Houston Texans\", \"CHI\": \"Chicago Bears\", \"TAM\": \"Tampa Bay Buccaneers\",\n",
    "    \"NYJ\": \"New York Jets\", \"NYG\": \"New York Giants\", \"BUF\": \"Buffalo Bills\",\n",
    "    \"ARI\":\"Arizona Cardinals\", \"DAL\": \"Dallas Cowboys\",\"TEN\": \"Tennessee Titans\",\n",
    "    \"IND\": \"Indianapolis Colts\",\"JAX\": \"Jacksonville Jaguars\",\"SEA\": \"Seattle Seahawks\",\n",
    "    \"SFO\": \"San Francisco 49ers\",\"CIN\": \"Cincinnati Bengals\",\"ATL\": \"Atlanta Falcons\",\n",
    "    \"DEN\": \"Denver Broncos\", \"NWE\": \"New England Patriots\",\"PHI\": \"Philadelphia Eagles\",\n",
    "    \"NOR\": \"New Orleans Saints\",\"STL\": \"St. Louis Rams\",\"MIN\": \"Minnesota Vikings\",\n",
    "    \"CAR\": \"Carolina Panthers\",\"KAN\": \"Kansas City Chiefs\", \"SD\": \"San Diego Chargers\",\n",
    "    \"BAL\": \"Baltimore Ravens\",\"GNB\": \"Green Bay Packers\", \"MIA\": \"Miami Dolphins\",\n",
    "    \"DET\": \"Detroit Lions\", \"WAS\": \"Washington Redskins\",\"OAK\": \"Oakland Raiders\",\n",
    "    \"PIT\": \"Pittsburgh Steelers\", \"CLE\": \"Cleveland Browns\"})\n",
    "            \n",
    "    if (y==2016):\n",
    "        table_df[\"Team\"] = table_df[\"Team\"].map({\n",
    "    \"HOU\": \"Houston Texans\", \"CHI\": \"Chicago Bears\", \"TAM\": \"Tampa Bay Buccaneers\",\n",
    "    \"NYJ\": \"New York Jets\", \"NYG\": \"New York Giants\", \"BUF\": \"Buffalo Bills\",\n",
    "    \"ARI\":\"Arizona Cardinals\", \"DAL\": \"Dallas Cowboys\",\"TEN\": \"Tennessee Titans\",\n",
    "    \"IND\": \"Indianapolis Colts\",\"JAX\": \"Jacksonville Jaguars\",\"SEA\": \"Seattle Seahawks\",\n",
    "    \"SFO\": \"San Francisco 49ers\",\"CIN\": \"Cincinnati Bengals\",\"ATL\": \"Atlanta Falcons\",\n",
    "    \"DEN\": \"Denver Broncos\", \"NWE\": \"New England Patriots\",\"PHI\": \"Philadelphia Eagles\",\n",
    "    \"NOR\": \"New Orleans Saints\",\"LAR\": \"Los Angeles Rams\",\"MIN\": \"Minnesota Vikings\",\n",
    "    \"CAR\": \"Carolina Panthers\",\"KAN\": \"Kansas City Chiefs\", \"SD\": \"San Diego Chargers\",\n",
    "    \"BAL\": \"Baltimore Ravens\",\"GNB\": \"Green Bay Packers\", \"MIA\": \"Miami Dolphins\",\n",
    "    \"DET\": \"Detroit Lions\", \"WAS\": \"Washington Redskins\",\"OAK\": \"Oakland Raiders\",\n",
    "    \"PIT\": \"Pittsburgh Steelers\", \"CLE\": \"Cleveland Browns\"})\n",
    "            \n",
    "    \n",
    "    if y>2016 and y<2020: \n",
    "        table_df[\"Team\"] = table_df[\"Team\"].map({\n",
    "    \"HOU\": \"Houston Texans\", \"CHI\": \"Chicago Bears\", \"TAM\": \"Tampa Bay Buccaneers\",\n",
    "    \"NYJ\": \"New York Jets\", \"NYG\": \"New York Giants\", \"BUF\": \"Buffalo Bills\",\n",
    "    \"ARI\":\"Arizona Cardinals\", \"DAL\": \"Dallas Cowboys\",\"TEN\": \"Tennessee Titans\",\n",
    "    \"IND\": \"Indianapolis Colts\",\"JAX\": \"Jacksonville Jaguars\",\"SEA\": \"Seattle Seahawks\",\n",
    "    \"SFO\": \"San Francisco 49ers\",\"CIN\": \"Cincinnati Bengals\",\"ATL\": \"Atlanta Falcons\",\n",
    "    \"DEN\": \"Denver Broncos\", \"NWE\": \"New England Patriots\",\"PHI\": \"Philadelphia Eagles\",\n",
    "    \"NOR\": \"New Orleans Saints\",\"LAR\": \"Los Angeles Rams\",\"MIN\": \"Minnesota Vikings\",\n",
    "    \"CAR\": \"Carolina Panthers\",\"KAN\": \"Kansas City Chiefs\", \"LAC\": \"Los Angeles Chargers\",\n",
    "    \"BAL\": \"Baltimore Ravens\",\"GNB\": \"Green Bay Packers\", \"MIA\": \"Miami Dolphins\",\n",
    "    \"DET\": \"Detroit Lions\", \"WAS\": \"Washington Redskins\",\"OAK\": \"Oakland Raiders\",\n",
    "    \"PIT\": \"Pittsburgh Steelers\", \"CLE\": \"Cleveland Browns\"})\n",
    "            \n",
    "    if (y==2020):     \n",
    "        table_df[\"Team\"] = table_df[\"Team\"].map({\n",
    "    \"HOU\": \"Houston Texans\", \"CHI\": \"Chicago Bears\", \"TAM\": \"Tampa Bay Buccaneers\",\n",
    "    \"NYJ\": \"New York Jets\", \"NYG\": \"New York Giants\", \"BUF\": \"Buffalo Bills\",\n",
    "    \"ARI\":\"Arizona Cardinals\", \"DAL\": \"Dallas Cowboys\",\"TEN\": \"Tennessee Titans\",\n",
    "    \"IND\": \"Indianapolis Colts\",\"JAX\": \"Jacksonville Jaguars\",\"SEA\": \"Seattle Seahawks\",\n",
    "    \"SFO\": \"San Francisco 49ers\",\"CIN\": \"Cincinnati Bengals\",\"ATL\": \"Atlanta Falcons\",\n",
    "    \"DEN\": \"Denver Broncos\", \"NWE\": \"New England Patriots\",\"PHI\": \"Philadelphia Eagles\",\n",
    "    \"NOR\": \"New Orleans Saints\",\"LAR\": \"Los Angeles Rams\",\"MIN\": \"Minnesota Vikings\",\n",
    "    \"CAR\": \"Carolina Panthers\",\"KAN\": \"Kansas City Chiefs\", \"LAC\": \"Los Angeles Chargers\",\n",
    "    \"BAL\": \"Baltimore Ravens\",\"GNB\": \"Green Bay Packers\", \"MIA\": \"Miami Dolphins\",\n",
    "    \"DET\": \"Detroit Lions\", \"WAS\": \"Washington Football Team\",\"LVR\": \"Las Vegas Raiders\",\n",
    "    \"PIT\": \"Pittsburgh Steelers\", \"CLE\": \"Cleveland Browns\"})\n",
    "    \n",
    "    table_df = table_df.rename(columns={\"Team\":\"team\"})\n",
    "    df_list.append(table_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70a60a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "defense = pd.concat(df_list)\n",
    "defense.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e11345f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#A PROBLEM COMES UP WHEN WEBSCRAPING FROM THIS PARTICULAR SOURCE: IN THE TABLE, EVERY 20-30 ROWS, \n",
    "# THERE IS A REPEATED LABEL ROW, WHICH NEEDS TO BE DELETED FROM THE DF\n",
    "# THEY LOOK LIKE THIS\n",
    "defense[defense[\"Played\"]==\"G\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1a518a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Removing NULL/Labeling Observations/Rows. 308 of them have to be removed\n",
    "lenDEF = len(defense)\n",
    "gs = defense[\"Played\"].value_counts()[\"G\"]\n",
    "print(\"Original length of defense is \" + str(lenDEF) + \". There are \" + str(gs) + \" null rows in this DF. Therefore, \\nif done correctly, the final\\nlength of 'defense' should be: \" + str(lenDEF-gs))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d90205",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete = defense[defense['Played']=='G']\n",
    "defense = defense.drop(delete.index)\n",
    "print(\"Now, 'defense' DF length is: \" + str(len(defense)) +\"! We've successfully removed all of the null rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739ee2b2",
   "metadata": {},
   "source": [
    "The dtypes are not correct so we will update them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6b4ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING DTYPES\n",
    "def_cols = ['Age', 'Played','Started','Int','Pass Def','FF','FR','Sack','Comb','Solo','Ast','TFL','QBHits']\n",
    "defense[def_cols] = defense[def_cols].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeef93e",
   "metadata": {},
   "source": [
    "Dtypes are now good to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6dd05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "defense[\"pos\"].value_counts().head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780b58ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generalizing specific defense positions such as ROLB or LOLB to OLB.\n",
    "DEF_dict = {\"LB\": \"OLB/DE\",\"ROLB/LIL\": \"OLB/DE\",\"ROLB/RIL\": \"OLB/DE\",\"LOLB\": \"OLB/DE\",\"ROLB\": \"OLB/DE\",\"ROLB/LOL\": \"OLB/DE\",\"LB-ROLB\": \"OLB/DE\",\"OLB\": \"OLB/DE\",\"LLB-ROLB\": \"OLB/DE\",\"LB-LDE\":\"OLB/DE\",\"RDE/LOLB\": \"OLB/DE\",\"DE-LOLB\": \"OLB/DE\",\"DE-ROLB\": \"OLB/DE\",\"LDE\": \"OLB/DE\",\"RDE\": \"OLB/DE\",\"DE\": \"OLB/DE\",\"LDE/RDE\": \"OLB/DE\",\"DE-RDE\": \"OLB/DE\",\"RDE/LDE\": \"OLB/DE\",\"LDE/LDT\": \"DT\",\"LDE/NT\": \"OLB/DE\",\"RDE/LDT\": \"DT\",\"DE/DT\": \"DT\",\"RCB\": \"CB\",\"LCB\": \"CB\",\"DB-LCB\": \"CB\", \"DB-RCB/L\": \"CB\",\"DB-RCB\": \"CB\",\"LCB/RCB\": \"CB\",\"CB\": \"CB\",\"CB/SS\": \"CB\",\"CB-DB\": \"CB\",\"RCB/LCB\": \"CB\",\"RCB/DB\": \"CB\",\"RCB/FS\": \"CB\",\"RCB/SS\": \"CB\",\"LCB/FS\": \"CB\",\"DT-RDE\": \"DT\",\"DT/DE\": \"DT\", \"RDT\": \"DT\",\"LDT\": \"DT\",\"DT\": \"DT\", \"LDT/RDT\": \"DT\", \"DT-FB\": \"DT\", \"NT-RDT\": \"DT\", \"RDT/LDT\": \"DT\", \"DT-NT\": \"DT\"}\n",
    "defense[\"pos\"] = defense[\"pos\"].map(DEF_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde8f286",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "defense['pos'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01b2375",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new DataFrames for each position we'll be examining. With defense, they are DE/OLB, DT, and CB\n",
    "DE_df = defense[defense[\"pos\"]==\"DE\"]\n",
    "DT_df = defense[defense[\"pos\"]==\"DT\"]\n",
    "CB_df = defense[defense[\"pos\"]==\"CB\"]\n",
    "OLB_df = defense[defense[\"pos\"]==\"OLB\"]\n",
    "OLB_DE_df = defense[(defense[\"pos\"]==\"OLB/DE\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52569adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTs = cap_wins.merge(DT_df, on=[\"Player\", \"season\", \"pos\",], how='inner')\n",
    "DTs = DTs.drop(columns=[\"team_y\"])\n",
    "DTs = DTs.rename(columns={\"team_x\":\"team\"})\n",
    "\n",
    "CBs = cap_wins.merge(CB_df, on=[\"Player\", \"season\", \"pos\"], how='inner')\n",
    "CBs = CBs.drop(columns=[\"team_y\"])\n",
    "CBs = CBs.rename(columns={\"team_x\":\"team\"})\n",
    "\n",
    "OLBs_DEs = cap_wins.merge(OLB_DE_df, on=[\"Player\", \"season\",'pos'], how='inner')\n",
    "OLBs_DEs = OLBs_DEs.rename(columns={\"Season Wins_x\t\":\"Season Wins\"})\n",
    "OLBs_DEs = OLBs_DEs.drop(columns=[\"team_y\"])\n",
    "OLBs_DEs = OLBs_DEs.rename(columns={\"team_x\":\"team\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db63e603",
   "metadata": {},
   "source": [
    "Now we have each defensive position separated into their respective position groups. We are in the clear to run the separate models for each defensive position group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e515e930",
   "metadata": {},
   "source": [
    "## OLB/DE Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6692b5af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Choosing test features\n",
    "OLBs_DEsfeats = ['Age', 'Played', 'Started', 'Int', 'Pass Def', 'FF', 'FR','Sack', 'Comb', 'Solo', 'Ast', 'TFL', 'QBHits']\n",
    "#Assigning X (features/attributes)\n",
    "x = OLBs_DEs[OLBs_DEsfeats]\n",
    "#Assigning Y (label/predicted val)\n",
    "y = OLBs_DEs['Season Wins']\n",
    "\n",
    "\n",
    "#Split the data into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5, random_state=10)\n",
    "\n",
    "#Standardizing the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_sc = scaler.transform(x_train)\n",
    "x_test_sc = scaler.transform(x_test)\n",
    "\n",
    "\n",
    "#Setting up Linear Regression Model\n",
    "linReg = LinearRegression()\n",
    "linReg.fit(x_train_sc, y_train)\n",
    "\n",
    "#Letting model make prediction\n",
    "y_test_pred = linReg.predict(x_test_sc)\n",
    "y_train_pred = linReg.predict(x_train_sc)\n",
    "\n",
    "\n",
    "#Checking MAE, MSE, and RMSE\n",
    "vMAE = (metrics.mean_absolute_error(y_test, y_test_pred))\n",
    "tMAE = (metrics.mean_absolute_error(y_train, y_train_pred))\n",
    "cMAE = np.mean(-cross_val_score(linReg, x, y, cv=5, scoring=\"neg_mean_absolute_error\"))\n",
    "\n",
    "\n",
    "vMSE = (metrics.mean_squared_error(y_test, y_test_pred))\n",
    "tMSE = (metrics.mean_squared_error(y_train, y_train_pred))\n",
    "cross_val_mse = np.mean(-cross_val_score(linReg, x, y, cv=5, scoring=\"neg_mean_squared_error\"))\n",
    "\n",
    "vRMSE = math.sqrt(vMSE)\n",
    "tRMSE = math.sqrt(tMSE)\n",
    "cRMSE = math.sqrt(cross_val_mse)\n",
    "\n",
    "print(\"Testing MAE:\")\n",
    "print(tMAE)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"5-Fold Cross Validation MAE:\")\n",
    "print(cMAE)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Testing RMSE:\")\n",
    "print(tRMSE)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"5-Fold Cross Validation RMSE:\")\n",
    "print(cRMSE)\n",
    "OLB_DE_vMAE = cMAE\n",
    "OLB_DE_vRMSE = cRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b897b548",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLBDEdrop = ['cap_hit','pos', 'Age', 'Played', 'Started', 'Int', 'Pass Def', 'FF', 'FR','Sack', 'Comb', 'Solo', 'Ast', 'TFL', 'QBHits']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572dbb48",
   "metadata": {},
   "source": [
    "Some of the highest paid players of this position will be in the training set, and some others will be in the test set. Since we need all of their predictions, we are making a new DataFrame that contains these players' positions, teams, season, cap percent, and most importantly, predicted wins and actual wins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa00409a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "OLBDE_Train = OLBs_DEs.loc[y_train.index]\n",
    "OLBDE_Train = OLBDE_Train.drop(columns = OLBDEdrop)\n",
    "OLBDE_Train\n",
    "OLBDE_Train[\"Predicted Wins\"] = y_train_pred\n",
    "#____________________________________________________________________________________________________________________________\n",
    "OLBDE_Test = OLBs_DEs.loc[y_test.index]\n",
    "OLBDE_Test = OLBDE_Test.drop(columns = OLBDEdrop)\n",
    "OLBDE_Test\n",
    "OLBDE_Test[\"Predicted Wins\"] = y_test_pred\n",
    "\n",
    "\n",
    "predictedOLBDEs = pd.concat([OLBDE_Test, OLBDE_Train])\n",
    "predictedOLBDEs['pos']='OLB/DE'\n",
    "predictedOLBDEs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de5aa1e",
   "metadata": {},
   "source": [
    "Because of issues with inconsistencies in the salary_cap dataset, and the statistical datasets we are using, we have faced unexpected issues when merging. This is causing NaN values in 'Season Wins' and 'Predicted Wins' for the players who have inconsistencies within both datasets. Of course, this is not ideal, but later on, we will try to solve this issue by imputing values for the missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4ddbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedOLBDEs_top7 = top7[top7['pos']=='OLB/DE']\n",
    "predictedOLBDEs_top7 = predictedOLBDEs_top7.merge(predictedOLBDEs, on=[\"Player\",\"pos\", \"season\",\"cap_percent\",'team'], how='left')\n",
    "predictedOLBDEs_top7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ac08a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictedOLBDEs_top7.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dfe99f",
   "metadata": {},
   "source": [
    "We have 68 NaN values. This means out of the 224 total OLB/DE top7 players, we are missing 68 of them. This is most likely due to differences in the datasets that we worked with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df31b6f",
   "metadata": {},
   "source": [
    "## CB Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9989aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing test features\n",
    "CBsfeats = ['Age', 'Played', 'Started', 'Int', 'Pass Def', 'FF', 'FR','Sack', 'Comb', 'Solo', 'Ast', 'TFL', 'QBHits']\n",
    "#Assigning X (features/attributes)\n",
    "x = CBs[CBsfeats]\n",
    "#Assigning Y (label/predicted val)\n",
    "y = CBs['Season Wins']\n",
    "\n",
    "\n",
    "#Split the data into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5, random_state=10)\n",
    "\n",
    "#Standardizing the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_sc = scaler.transform(x_train)\n",
    "x_test_sc = scaler.transform(x_test)\n",
    "\n",
    "\n",
    "#Setting up Linear Regression Model\n",
    "linReg = LinearRegression()\n",
    "linReg.fit(x_train_sc, y_train)\n",
    "\n",
    "#Letting model make prediction\n",
    "y_test_pred = linReg.predict(x_test_sc)\n",
    "y_train_pred = linReg.predict(x_train_sc)\n",
    "\n",
    "\n",
    "#Checking MAE, MSE, and RMSE\n",
    "vMAE = (metrics.mean_absolute_error(y_test, y_test_pred))\n",
    "tMAE = (metrics.mean_absolute_error(y_train, y_train_pred))\n",
    "cMAE = np.mean(-cross_val_score(linReg, x, y, cv=5, scoring=\"neg_mean_absolute_error\"))\n",
    "\n",
    "\n",
    "vMSE = (metrics.mean_squared_error(y_test, y_test_pred))\n",
    "tMSE = (metrics.mean_squared_error(y_train, y_train_pred))\n",
    "cross_val_mse = np.mean(-cross_val_score(linReg, x, y, cv=5, scoring=\"neg_mean_squared_error\"))\n",
    "\n",
    "vRMSE = math.sqrt(vMSE)\n",
    "tRMSE = math.sqrt(tMSE)\n",
    "cRMSE = math.sqrt(cross_val_mse)\n",
    "\n",
    "print(\"Testing MAE:\")\n",
    "print(tMAE)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"5-Fold Cross Validation MAE:\")\n",
    "print(cMAE)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Testing RMSE:\")\n",
    "print(tRMSE)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"5-Fold Cross Validation RMSE:\")\n",
    "print(cRMSE)\n",
    "CB_vMAE = cMAE\n",
    "CB_vRMSE = cRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded89589",
   "metadata": {},
   "outputs": [],
   "source": [
    "CBdrop = ['cap_hit','pos', 'Age', 'Played', 'Started', 'Int', 'Pass Def', 'FF', 'FR','Sack', 'Comb', 'Solo', 'Ast', 'TFL', 'QBHits']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4de02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CB_Train = CBs.loc[y_train.index]\n",
    "CB_Train = CB_Train.drop(columns = CBdrop)\n",
    "CB_Train[\"Predicted Wins\"] = y_train_pred\n",
    "#____________________________________________________________________________________________________________________________\n",
    "CB_Test = CBs.loc[y_test.index]\n",
    "CB_Test = CB_Test.drop(columns = CBdrop)\n",
    "CB_Test[\"Predicted Wins\"] = y_test_pred\n",
    "\n",
    "\n",
    "predictedCBs = pd.concat([CB_Test, CB_Train])\n",
    "predictedCBs['pos']='CB'\n",
    "predictedCBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068994d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedCBs_top7 = top7[top7['pos']=='CB']\n",
    "predictedCBs_top7 = predictedCBs_top7.merge(predictedCBs, on=[\"Player\",\"pos\", \"season\",\"cap_percent\",'team'], how='left')\n",
    "predictedCBs_top7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe9a50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedCBs_top7.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbdee22",
   "metadata": {},
   "source": [
    "## DT Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec72dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing test features\n",
    "DTsfeats = ['Age', 'Played', 'Started', 'Int', 'Pass Def', 'FF', 'FR','Sack', 'Comb', 'Solo', 'Ast', 'TFL', 'QBHits']\n",
    "#Assigning X (features/attributes)\n",
    "x = DTs[DTsfeats]\n",
    "#Assigning Y (label/predicted val)\n",
    "y = DTs['Season Wins']\n",
    "\n",
    "\n",
    "#Split the data into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5, random_state=10)\n",
    "\n",
    "#Standardizing the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_sc = scaler.transform(x_train)\n",
    "x_test_sc = scaler.transform(x_test)\n",
    "\n",
    "\n",
    "#Setting up Linear Regression Model\n",
    "linReg = LinearRegression()\n",
    "linReg.fit(x_train_sc, y_train)\n",
    "\n",
    "#Letting model make prediction\n",
    "y_test_pred = linReg.predict(x_test_sc)\n",
    "y_train_pred = linReg.predict(x_train_sc)\n",
    "\n",
    "\n",
    "#Checking MAE, MSE, and RMSE\n",
    "vMAE = (metrics.mean_absolute_error(y_test, y_test_pred))\n",
    "tMAE = (metrics.mean_absolute_error(y_train, y_train_pred))\n",
    "cMAE = np.mean(-cross_val_score(linReg, x, y, cv=5, scoring=\"neg_mean_absolute_error\"))\n",
    "\n",
    "\n",
    "vMSE = (metrics.mean_squared_error(y_test, y_test_pred))\n",
    "tMSE = (metrics.mean_squared_error(y_train, y_train_pred))\n",
    "cross_val_mse = np.mean(-cross_val_score(linReg, x, y, cv=5, scoring=\"neg_mean_squared_error\"))\n",
    "\n",
    "vRMSE = math.sqrt(vMSE)\n",
    "tRMSE = math.sqrt(tMSE)\n",
    "cRMSE = math.sqrt(cross_val_mse)\n",
    "\n",
    "print(\"Testing MAE:\")\n",
    "print(tMAE)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"5-Fold Cross Validation MAE:\")\n",
    "print(cMAE)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Testing RMSE:\")\n",
    "print(tRMSE)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"5-Fold Cross Validation RMSE:\")\n",
    "print(cRMSE)\n",
    "DT_vMAE = cMAE\n",
    "DT_vRMSE = cRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f28aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTdrop = ['cap_hit','pos', 'Age', 'Played', 'Started', 'Int', 'Pass Def', 'FF', 'FR','Sack', 'Comb', 'Solo', 'Ast', 'TFL', 'QBHits']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ded78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_Train = DTs.loc[y_train.index]\n",
    "DT_Train = DT_Train.drop(columns = DTdrop)\n",
    "DT_Train[\"Predicted Wins\"] = y_train_pred\n",
    "#____________________________________________________________________________________________________________________________\n",
    "DT_Test = DTs.loc[y_test.index]\n",
    "DT_Test = DT_Test.drop(columns = DTdrop)\n",
    "DT_Test[\"Predicted Wins\"] = y_test_pred\n",
    "\n",
    "\n",
    "predictedDTs = pd.concat([DT_Test, DT_Train])\n",
    "predictedDTs['pos']='DT'\n",
    "predictedDTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12a0e78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictedDTs_top7 = top7[top7['pos']=='DT']\n",
    "predictedDTs_top7 = predictedDTs_top7.merge(predictedDTs, on=[\"Player\",\"pos\", \"season\",\"cap_percent\",'team'], how='left')\n",
    "predictedDTs_top7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3148fb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedDTs_top7.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e36998",
   "metadata": {},
   "source": [
    "## QB WebScraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60023cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WEB-SCRAPING FOR LOOP RESPONSIBLE FOR QUARTERBACKS\n",
    "\n",
    "years = [2014,2015,2016,2017,2018,2019,2020]\n",
    "QB_list = []\n",
    "for y in years:\n",
    "    \n",
    "    url = 'https://www.pro-football-reference.com/years/' + str(y) + '/passing.htm'\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "\n",
    "    b = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(b.content)\n",
    "    table = soup.find(\"table\")\n",
    "    table_df = pd.read_html(str(table))[0]\n",
    "    \n",
    "    table_df = table_df.fillna(value=0)\n",
    "    table_df[\"season\"]=y\n",
    "    \n",
    "    table_df = table_df.drop(columns=[\"Rk\",])\n",
    "    table_df = table_df.rename(columns={\"Tm\":\"Team\", \"Pos\":\"pos\",\"G\":\"Played\", \"GS\":\"Started\", \"Cmp\":\"Completed\", \"Att\":\"Attempted\", \"Sk\":\"Times Sacked\", \"Yds.1\":\"Sacked -Yards\"})\n",
    "    table_df[\"Player\"] = table_df[\"Player\"].apply(lambda x: x.replace(\"*\",\"\").replace(\"+\",\"\")) \n",
    "    \n",
    "\n",
    "    if (y<=2015):\n",
    "        table_df[\"Team\"] = table_df[\"Team\"].map({\n",
    "    \"HOU\": \"Houston Texans\", \"CHI\": \"Chicago Bears\", \"TAM\": \"Tampa Bay Buccaneers\",\n",
    "    \"NYJ\": \"New York Jets\", \"NYG\": \"New York Giants\", \"BUF\": \"Buffalo Bills\",\n",
    "    \"ARI\":\"Arizona Cardinals\", \"DAL\": \"Dallas Cowboys\",\"TEN\": \"Tennessee Titans\",\n",
    "    \"IND\": \"Indianapolis Colts\",\"JAX\": \"Jacksonville Jaguars\",\"SEA\": \"Seattle Seahawks\",\n",
    "    \"SFO\": \"San Francisco 49ers\",\"CIN\": \"Cincinnati Bengals\",\"ATL\": \"Atlanta Falcons\",\n",
    "    \"DEN\": \"Denver Broncos\", \"NWE\": \"New England Patriots\",\"PHI\": \"Philadelphia Eagles\",\n",
    "    \"NOR\": \"New Orleans Saints\",\"STL\": \"St. Louis Rams\",\"MIN\": \"Minnesota Vikings\",\n",
    "    \"CAR\": \"Carolina Panthers\",\"KAN\": \"Kansas City Chiefs\", \"SD\": \"San Diego Chargers\",\n",
    "    \"BAL\": \"Baltimore Ravens\",\"GNB\": \"Green Bay Packers\", \"MIA\": \"Miami Dolphins\",\n",
    "    \"DET\": \"Detroit Lions\", \"WAS\": \"Washington Redskins\",\"OAK\": \"Oakland Raiders\",\n",
    "    \"PIT\": \"Pittsburgh Steelers\", \"CLE\": \"Cleveland Browns\"})\n",
    "            \n",
    "    if (y==2016):\n",
    "        table_df[\"Team\"] = table_df[\"Team\"].map({\n",
    "    \"HOU\": \"Houston Texans\", \"CHI\": \"Chicago Bears\", \"TAM\": \"Tampa Bay Buccaneers\",\n",
    "    \"NYJ\": \"New York Jets\", \"NYG\": \"New York Giants\", \"BUF\": \"Buffalo Bills\",\n",
    "    \"ARI\":\"Arizona Cardinals\", \"DAL\": \"Dallas Cowboys\",\"TEN\": \"Tennessee Titans\",\n",
    "    \"IND\": \"Indianapolis Colts\",\"JAX\": \"Jacksonville Jaguars\",\"SEA\": \"Seattle Seahawks\",\n",
    "    \"SFO\": \"San Francisco 49ers\",\"CIN\": \"Cincinnati Bengals\",\"ATL\": \"Atlanta Falcons\",\n",
    "    \"DEN\": \"Denver Broncos\", \"NWE\": \"New England Patriots\",\"PHI\": \"Philadelphia Eagles\",\n",
    "    \"NOR\": \"New Orleans Saints\",\"LAR\": \"Los Angeles Rams\",\"MIN\": \"Minnesota Vikings\",\n",
    "    \"CAR\": \"Carolina Panthers\",\"KAN\": \"Kansas City Chiefs\", \"SD\": \"San Diego Chargers\",\n",
    "    \"BAL\": \"Baltimore Ravens\",\"GNB\": \"Green Bay Packers\", \"MIA\": \"Miami Dolphins\",\n",
    "    \"DET\": \"Detroit Lions\", \"WAS\": \"Washington Redskins\",\"OAK\": \"Oakland Raiders\",\n",
    "    \"PIT\": \"Pittsburgh Steelers\", \"CLE\": \"Cleveland Browns\"})\n",
    "            \n",
    "    if y>2016 and y<2020: \n",
    "        table_df[\"Team\"] = table_df[\"Team\"].map({\n",
    "    \"HOU\": \"Houston Texans\", \"CHI\": \"Chicago Bears\", \"TAM\": \"Tampa Bay Buccaneers\",\n",
    "    \"NYJ\": \"New York Jets\", \"NYG\": \"New York Giants\", \"BUF\": \"Buffalo Bills\",\n",
    "    \"ARI\":\"Arizona Cardinals\", \"DAL\": \"Dallas Cowboys\",\"TEN\": \"Tennessee Titans\",\n",
    "    \"IND\": \"Indianapolis Colts\",\"JAX\": \"Jacksonville Jaguars\",\"SEA\": \"Seattle Seahawks\",\n",
    "    \"SFO\": \"San Francisco 49ers\",\"CIN\": \"Cincinnati Bengals\",\"ATL\": \"Atlanta Falcons\",\n",
    "    \"DEN\": \"Denver Broncos\", \"NWE\": \"New England Patriots\",\"PHI\": \"Philadelphia Eagles\",\n",
    "    \"NOR\": \"New Orleans Saints\",\"LAR\": \"Los Angeles Rams\",\"MIN\": \"Minnesota Vikings\",\n",
    "    \"CAR\": \"Carolina Panthers\",\"KAN\": \"Kansas City Chiefs\", \"LAC\": \"Los Angeles Chargers\",\n",
    "    \"BAL\": \"Baltimore Ravens\",\"GNB\": \"Green Bay Packers\", \"MIA\": \"Miami Dolphins\",\n",
    "    \"DET\": \"Detroit Lions\", \"WAS\": \"Washington Redskins\",\"OAK\": \"Oakland Raiders\",\n",
    "    \"PIT\": \"Pittsburgh Steelers\", \"CLE\": \"Cleveland Browns\"})\n",
    "            \n",
    "    if (y==2020):     \n",
    "        table_df[\"Team\"] = table_df[\"Team\"].map({\n",
    "    \"HOU\": \"Houston Texans\", \"CHI\": \"Chicago Bears\", \"TAM\": \"Tampa Bay Buccaneers\",\n",
    "    \"NYJ\": \"New York Jets\", \"NYG\": \"New York Giants\", \"BUF\": \"Buffalo Bills\",\n",
    "    \"ARI\":\"Arizona Cardinals\", \"DAL\": \"Dallas Cowboys\",\"TEN\": \"Tennessee Titans\",\n",
    "    \"IND\": \"Indianapolis Colts\",\"JAX\": \"Jacksonville Jaguars\",\"SEA\": \"Seattle Seahawks\",\n",
    "    \"SFO\": \"San Francisco 49ers\",\"CIN\": \"Cincinnati Bengals\",\"ATL\": \"Atlanta Falcons\",\n",
    "    \"DEN\": \"Denver Broncos\", \"NWE\": \"New England Patriots\",\"PHI\": \"Philadelphia Eagles\",\n",
    "    \"NOR\": \"New Orleans Saints\",\"LAR\": \"Los Angeles Rams\",\"MIN\": \"Minnesota Vikings\",\n",
    "    \"CAR\": \"Carolina Panthers\",\"KAN\": \"Kansas City Chiefs\", \"LAC\": \"Los Angeles Chargers\",\n",
    "    \"BAL\": \"Baltimore Ravens\",\"GNB\": \"Green Bay Packers\", \"MIA\": \"Miami Dolphins\",\n",
    "    \"DET\": \"Detroit Lions\", \"WAS\": \"Washington Football Team\",\"LVR\": \"Las Vegas Raiders\",\n",
    "    \"PIT\": \"Pittsburgh Steelers\", \"CLE\": \"Cleveland Browns\"})\n",
    "    \n",
    "    table_df = table_df.rename(columns={\"Team\":\"team\"})\n",
    "    QB_list.append(table_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91088bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "QB_df = pd.concat(QB_list)\n",
    "QB_df = QB_df[QB_df[\"pos\"]==\"QB\"]\n",
    "cols = ['Age','Played', 'Started','Completed', 'Attempted', 'Cmp%', 'Yds', 'TD', 'TD%', 'Int', 'Int%','1D', 'Lng', 'Y/A', 'AY/A', 'Y/C', 'Y/G', 'Rate', 'QBR', 'Times Sacked','Sacked -Yards', 'Sk%', 'NY/A', 'ANY/A', '4QC', 'GWD', 'season']\n",
    "QB_df[cols] = QB_df[cols].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0964d0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "QB_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4c1ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "QBs = cap_wins.merge(QB_df, on=[\"Player\", \"season\", \"pos\"], how='inner')\n",
    "QBs[\"team_y\"].isna().sum()\n",
    "QBs = QBs.drop(columns=[\"team_y\"])\n",
    "QBs = QBs.rename(columns={\"team_x\":\"team\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00fc48b",
   "metadata": {},
   "source": [
    "## QB Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6498161f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing test features\n",
    "QBfeats = ['Age', 'Played', 'Started', 'Completed', 'Attempted', 'Cmp%', 'Yds','TD', 'TD%', 'Int', 'Int%', '1D', 'Lng', 'Y/A', 'AY/A', 'Y/C', 'Y/G', 'Rate', 'QBR', 'Times Sacked', 'Sacked -Yards', 'Sk%', 'NY/A', 'ANY/A','4QC', 'GWD']\n",
    "#Assigning X (features/attributes)\n",
    "x = QBs[QBfeats]\n",
    "#Assigning Y (label/predicted val)\n",
    "y = QBs['Season Wins']\n",
    "\n",
    "\n",
    "#Split the data into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1000)\n",
    "\n",
    "#Standardizing the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_sc = scaler.transform(x_train)\n",
    "x_test_sc = scaler.transform(x_test)\n",
    "\n",
    "\n",
    "#Setting up Linear Regression Model\n",
    "linReg = LinearRegression()\n",
    "linReg.fit(x_train_sc, y_train)\n",
    "\n",
    "#Letting model make prediction\n",
    "y_test_pred = linReg.predict(x_test_sc)\n",
    "y_train_pred = linReg.predict(x_train_sc)\n",
    "\n",
    "\n",
    "#Checking MAE, MSE, and RMSE\n",
    "vMAE = (metrics.mean_absolute_error(y_test, y_test_pred))\n",
    "tMAE = (metrics.mean_absolute_error(y_train, y_train_pred))\n",
    "cMAE = np.mean(-cross_val_score(linReg, x, y, cv=5, scoring=\"neg_mean_absolute_error\"))\n",
    "\n",
    "\n",
    "vMSE = (metrics.mean_squared_error(y_test, y_test_pred))\n",
    "tMSE = (metrics.mean_squared_error(y_train, y_train_pred))\n",
    "cross_val_mse = np.mean(-cross_val_score(linReg, x, y, cv=5, scoring=\"neg_mean_squared_error\"))\n",
    "\n",
    "vRMSE = math.sqrt(vMSE)\n",
    "tRMSE = math.sqrt(tMSE)\n",
    "cRMSE = math.sqrt(cross_val_mse)\n",
    "\n",
    "print(\"Testing MAE:\")\n",
    "print(tMAE)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"5-Fold Cross Validation MAE:\")\n",
    "print(cMAE)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Testing RMSE:\")\n",
    "print(tRMSE)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"5-Fold Cross Validation RMSE:\")\n",
    "print(cRMSE)\n",
    "QB_vMAE = cMAE\n",
    "QB_vRMSE = cRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03158192",
   "metadata": {},
   "outputs": [],
   "source": [
    "QBdrop = ['pos', 'cap_percent', 'Age','Played', 'Started', 'QBrec', 'Completed', 'Attempted', 'Cmp%', 'Yds','TD', 'TD%', 'Int', 'Int%', '1D', 'Lng', 'Y/A', 'AY/A', 'Y/C', 'Y/G','Rate', 'QBR', 'Times Sacked', 'Sacked -Yards', 'Sk%', 'NY/A', 'ANY/A','4QC', 'GWD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1fb77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "QB_Train = QBs.loc[y_train.index]\n",
    "QB_Train = QB_Train.drop(columns = QBdrop)\n",
    "QB_Train[\"Predicted Wins\"] = y_train_pred\n",
    "#____________________________________________________________________________________________________________________________\n",
    "QB_Test = QBs.loc[y_test.index]\n",
    "QB_Test = QB_Test.drop(columns = QBdrop)\n",
    "QB_Test[\"Predicted Wins\"] = y_test_pred\n",
    "\n",
    "\n",
    "predictedQBs = pd.concat([QB_Test, QB_Train])\n",
    "predictedQBs['pos']='QB'\n",
    "predictedQBs = predictedQBs.drop(columns=[\"cap_hit\",])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff085ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedQBs_top7 = top7[top7['pos']=='QB']\n",
    "predictedQBs_top7 = predictedQBs_top7.merge(predictedQBs, on=[\"Player\",\"pos\", \"season\", \"team\"], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539f599b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedQBs_top7.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a110e560",
   "metadata": {},
   "source": [
    "## WR WebScraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79da2f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WEB-SCRAPING FOR LOOP RESPONSIBLE FOR WIDE RECEIVERS\n",
    "\n",
    "years = [2014,2015,2016,2017,2018,2019,2020]\n",
    "WR_list = []\n",
    "for y in years:\n",
    "    \n",
    "    url = 'https://www.pro-football-reference.com/years/' + str(y) + '/receiving.htm'\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "\n",
    "    b = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(b.content)\n",
    "    table = soup.find(\"table\")\n",
    "    table_df = pd.read_html(str(table))[0]\n",
    "    \n",
    "    table_df = table_df.fillna(value=0)\n",
    "    table_df[\"season\"]=y\n",
    "    \n",
    "    table_df = table_df.drop(columns=[\"Rk\",])\n",
    "    table_df = table_df.rename(columns={\"Tm\":\"Team\", \"Pos\":\"pos\",\"G\":\"Played\", \"GS\":\"Started\", \"Tgt\":\"Targets\", \"Rec\":\"Received\"})\n",
    "    table_df[\"Player\"] = table_df[\"Player\"].apply(lambda x: x.replace(\"*\",\"\").replace(\"+\",\"\")) \n",
    "    table_df[\"Ctch%\"] = table_df[\"Ctch%\"].apply(lambda x: x.replace('%',\"\")) \n",
    "\n",
    "\n",
    "    if (y<=2015):\n",
    "        table_df[\"Team\"] = table_df[\"Team\"].map({\n",
    "    \"HOU\": \"Houston Texans\", \"CHI\": \"Chicago Bears\", \"TAM\": \"Tampa Bay Buccaneers\",\n",
    "    \"NYJ\": \"New York Jets\", \"NYG\": \"New York Giants\", \"BUF\": \"Buffalo Bills\",\n",
    "    \"ARI\":\"Arizona Cardinals\", \"DAL\": \"Dallas Cowboys\",\"TEN\": \"Tennessee Titans\",\n",
    "    \"IND\": \"Indianapolis Colts\",\"JAX\": \"Jacksonville Jaguars\",\"SEA\": \"Seattle Seahawks\",\n",
    "    \"SFO\": \"San Francisco 49ers\",\"CIN\": \"Cincinnati Bengals\",\"ATL\": \"Atlanta Falcons\",\n",
    "    \"DEN\": \"Denver Broncos\", \"NWE\": \"New England Patriots\",\"PHI\": \"Philadelphia Eagles\",\n",
    "    \"NOR\": \"New Orleans Saints\",\"STL\": \"St. Louis Rams\",\"MIN\": \"Minnesota Vikings\",\n",
    "    \"CAR\": \"Carolina Panthers\",\"KAN\": \"Kansas City Chiefs\", \"SD\": \"San Diego Chargers\",\n",
    "    \"BAL\": \"Baltimore Ravens\",\"GNB\": \"Green Bay Packers\", \"MIA\": \"Miami Dolphins\",\n",
    "    \"DET\": \"Detroit Lions\", \"WAS\": \"Washington Redskins\",\"OAK\": \"Oakland Raiders\",\n",
    "    \"PIT\": \"Pittsburgh Steelers\", \"CLE\": \"Cleveland Browns\"})\n",
    "            \n",
    "    if (y==2016):\n",
    "        table_df[\"Team\"] = table_df[\"Team\"].map({\n",
    "    \"HOU\": \"Houston Texans\", \"CHI\": \"Chicago Bears\", \"TAM\": \"Tampa Bay Buccaneers\",\n",
    "    \"NYJ\": \"New York Jets\", \"NYG\": \"New York Giants\", \"BUF\": \"Buffalo Bills\",\n",
    "    \"ARI\":\"Arizona Cardinals\", \"DAL\": \"Dallas Cowboys\",\"TEN\": \"Tennessee Titans\",\n",
    "    \"IND\": \"Indianapolis Colts\",\"JAX\": \"Jacksonville Jaguars\",\"SEA\": \"Seattle Seahawks\",\n",
    "    \"SFO\": \"San Francisco 49ers\",\"CIN\": \"Cincinnati Bengals\",\"ATL\": \"Atlanta Falcons\",\n",
    "    \"DEN\": \"Denver Broncos\", \"NWE\": \"New England Patriots\",\"PHI\": \"Philadelphia Eagles\",\n",
    "    \"NOR\": \"New Orleans Saints\",\"LAR\": \"Los Angeles Rams\",\"MIN\": \"Minnesota Vikings\",\n",
    "    \"CAR\": \"Carolina Panthers\",\"KAN\": \"Kansas City Chiefs\", \"SD\": \"San Diego Chargers\",\n",
    "    \"BAL\": \"Baltimore Ravens\",\"GNB\": \"Green Bay Packers\", \"MIA\": \"Miami Dolphins\",\n",
    "    \"DET\": \"Detroit Lions\", \"WAS\": \"Washington Redskins\",\"OAK\": \"Oakland Raiders\",\n",
    "    \"PIT\": \"Pittsburgh Steelers\", \"CLE\": \"Cleveland Browns\"})\n",
    "            \n",
    "    if y>2016 and y<2020: \n",
    "        table_df[\"Team\"] = table_df[\"Team\"].map({\n",
    "    \"HOU\": \"Houston Texans\", \"CHI\": \"Chicago Bears\", \"TAM\": \"Tampa Bay Buccaneers\",\n",
    "    \"NYJ\": \"New York Jets\", \"NYG\": \"New York Giants\", \"BUF\": \"Buffalo Bills\",\n",
    "    \"ARI\":\"Arizona Cardinals\", \"DAL\": \"Dallas Cowboys\",\"TEN\": \"Tennessee Titans\",\n",
    "    \"IND\": \"Indianapolis Colts\",\"JAX\": \"Jacksonville Jaguars\",\"SEA\": \"Seattle Seahawks\",\n",
    "    \"SFO\": \"San Francisco 49ers\",\"CIN\": \"Cincinnati Bengals\",\"ATL\": \"Atlanta Falcons\",\n",
    "    \"DEN\": \"Denver Broncos\", \"NWE\": \"New England Patriots\",\"PHI\": \"Philadelphia Eagles\",\n",
    "    \"NOR\": \"New Orleans Saints\",\"LAR\": \"Los Angeles Rams\",\"MIN\": \"Minnesota Vikings\",\n",
    "    \"CAR\": \"Carolina Panthers\",\"KAN\": \"Kansas City Chiefs\", \"LAC\": \"Los Angeles Chargers\",\n",
    "    \"BAL\": \"Baltimore Ravens\",\"GNB\": \"Green Bay Packers\", \"MIA\": \"Miami Dolphins\",\n",
    "    \"DET\": \"Detroit Lions\", \"WAS\": \"Washington Redskins\",\"OAK\": \"Oakland Raiders\",\n",
    "    \"PIT\": \"Pittsburgh Steelers\", \"CLE\": \"Cleveland Browns\"})\n",
    "            \n",
    "    if (y==2020):     \n",
    "        table_df[\"Team\"] = table_df[\"Team\"].map({\n",
    "    \"HOU\": \"Houston Texans\", \"CHI\": \"Chicago Bears\", \"TAM\": \"Tampa Bay Buccaneers\",\n",
    "    \"NYJ\": \"New York Jets\", \"NYG\": \"New York Giants\", \"BUF\": \"Buffalo Bills\",\n",
    "    \"ARI\":\"Arizona Cardinals\", \"DAL\": \"Dallas Cowboys\",\"TEN\": \"Tennessee Titans\",\n",
    "    \"IND\": \"Indianapolis Colts\",\"JAX\": \"Jacksonville Jaguars\",\"SEA\": \"Seattle Seahawks\",\n",
    "    \"SFO\": \"San Francisco 49ers\",\"CIN\": \"Cincinnati Bengals\",\"ATL\": \"Atlanta Falcons\",\n",
    "    \"DEN\": \"Denver Broncos\", \"NWE\": \"New England Patriots\",\"PHI\": \"Philadelphia Eagles\",\n",
    "    \"NOR\": \"New Orleans Saints\",\"LAR\": \"Los Angeles Rams\",\"MIN\": \"Minnesota Vikings\",\n",
    "    \"CAR\": \"Carolina Panthers\",\"KAN\": \"Kansas City Chiefs\", \"LAC\": \"Los Angeles Chargers\",\n",
    "    \"BAL\": \"Baltimore Ravens\",\"GNB\": \"Green Bay Packers\", \"MIA\": \"Miami Dolphins\",\n",
    "    \"DET\": \"Detroit Lions\", \"WAS\": \"Washington Football Team\",\"LVR\": \"Las Vegas Raiders\",\n",
    "    \"PIT\": \"Pittsburgh Steelers\", \"CLE\": \"Cleveland Browns\"})\n",
    "    \n",
    "    table_df = table_df.rename(columns={\"Team\":\"team\"})\n",
    "    WR_list.append(table_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc6765a",
   "metadata": {},
   "outputs": [],
   "source": [
    "WR_df = pd.concat(WR_list)\n",
    "WR_df = WR_df[WR_df[\"pos\"]==\"WR\"]\n",
    "features = ['Age', 'Played', 'Started', 'Targets', 'Received', 'Ctch%', 'Yds', 'Y/R', 'TD', '1D', 'Lng', 'Y/Tgt', 'R/G','Y/G', 'Fmb', 'season']\n",
    "WR_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a7923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "WR_df[features] = WR_df[features].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca111c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "WRs = cap_wins.merge(WR_df, on=[\"Player\", \"season\", \"pos\"], how='inner')\n",
    "WRs = WRs.drop(columns=[\"team_y\"])\n",
    "WRs = WRs.rename(columns={\"team_x\":\"team\"})\n",
    "WRs.drop_duplicates(subset=None, keep=\"first\", inplace=True)\n",
    "WRs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba7a2fd",
   "metadata": {},
   "source": [
    "## WR Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c020a469",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing test features\n",
    "WRfeats = ['Age','Played', 'Started', 'Targets', 'Received', 'Ctch%', 'Yds', 'Y/R', 'TD','1D', 'Lng', 'Y/Tgt', 'R/G', 'Y/G', 'Fmb']\n",
    "#Assigning X (features/attributes)\n",
    "x = WRs[WRfeats]\n",
    "#Assigning Y (label/predicted val)\n",
    "y = WRs['Season Wins']\n",
    "\n",
    "\n",
    "#Split the data into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1000)\n",
    "\n",
    "#Standardizing the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_sc = scaler.transform(x_train)\n",
    "x_test_sc = scaler.transform(x_test)\n",
    "\n",
    "\n",
    "#Setting up Linear Regression Model\n",
    "linReg = LinearRegression()\n",
    "linReg.fit(x_train_sc, y_train)\n",
    "\n",
    "#Letting model make prediction\n",
    "y_test_pred = linReg.predict(x_test_sc)\n",
    "y_train_pred = linReg.predict(x_train_sc)\n",
    "\n",
    "\n",
    "#Checking MAE, MSE, and RMSE\n",
    "vMAE = (metrics.mean_absolute_error(y_test, y_test_pred))\n",
    "tMAE = (metrics.mean_absolute_error(y_train, y_train_pred))\n",
    "cMAE = np.mean(-cross_val_score(linReg, x, y, cv=5, scoring=\"neg_mean_absolute_error\"))\n",
    "\n",
    "\n",
    "vMSE = (metrics.mean_squared_error(y_test, y_test_pred))\n",
    "tMSE = (metrics.mean_squared_error(y_train, y_train_pred))\n",
    "cross_val_mse = np.mean(-cross_val_score(linReg, x, y, cv=5, scoring=\"neg_mean_squared_error\"))\n",
    "\n",
    "vRMSE = math.sqrt(vMSE)\n",
    "tRMSE = math.sqrt(tMSE)\n",
    "cRMSE = math.sqrt(cross_val_mse)\n",
    "\n",
    "print(\"Testing MAE:\")\n",
    "print(tMAE)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"5-Fold Cross Validation MAE:\")\n",
    "print(cMAE)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Testing RMSE:\")\n",
    "print(tRMSE)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"5-Fold Cross Validation RMSE:\")\n",
    "print(cRMSE)\n",
    "WR_vMAE = cMAE\n",
    "WR_vRMSE = cRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d062def",
   "metadata": {},
   "outputs": [],
   "source": [
    "WRdrop = ['cap_hit', 'Age', 'Played', 'Started', 'Targets', 'Received','Ctch%', 'Yds', 'Y/R', 'TD', '1D', 'Lng', 'Y/Tgt', 'R/G', 'Y/G', 'Fmb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8ba58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "WR_Train = WRs.loc[y_train.index]\n",
    "WR_Train = WR_Train.drop(columns = WRdrop)\n",
    "WR_Train[\"Predicted Wins\"] = y_train_pred\n",
    "#____________________________________________________________________________________________________________________________\n",
    "WR_Test = WRs.loc[y_test.index]\n",
    "WR_Test = WR_Test.drop(columns = WRdrop)\n",
    "WR_Test[\"Predicted Wins\"] = y_test_pred\n",
    "\n",
    "\n",
    "predictedWRs = pd.concat([WR_Train, WR_Test])\n",
    "predictedWRs['pos']='WR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d105bb46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictedWRs_top7 = top7[top7['pos']=='WR']\n",
    "predictedWRs_top7\n",
    "predictedWRs_top7 = predictedWRs_top7.merge(predictedWRs, on=[\"Player\",\"pos\", \"season\", \"team\",'cap_percent'], how='left')\n",
    "predictedWRs_top7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9fda04",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedWRs_top7.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a411fa50",
   "metadata": {},
   "source": [
    "## LT DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc32a698",
   "metadata": {},
   "source": [
    "Due to the issue of using separate sources for data, some of our left tackles were listed as right tackles or tackles. To fix this issue we will replace all tackle info to LT. In our findings above, left tackle was one of the highest paying positions and right tackle was not. Also, our top7 function identifies the highest paying LT, so we will not have to worry about a RT getting pulled into a LT top7 spot.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37549f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(cap_wins.loc[(cap_wins['pos']=='LT') | (cap_wins['pos']==\"T\") | (cap_wins['pos']==\"RT\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775cd5a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LTs  = stats_tackles[['season',\"player\",'position','team_name','player_game_count','grades_offense','snap_counts_pass_block','snap_counts_run_block','penalties','pressures_allowed','sacks_allowed','grades_pass_block','grades_run_block','hits_allowed','hurries_allowed']].copy()\n",
    "LTs = stats_tackles.rename(columns={\"player\":\"Player\", \"position\":\"pos\"})\n",
    "LTs['pos'] = LTs['pos'].str.replace('T','LT')\n",
    "LTs = LTs[LTs['pos'] == \"LT\"]\n",
    "LTs = cap_wins.merge(LTs, on=[\"Player\", \"season\"], how='inner')\n",
    "LTs = LTs.rename(columns={\"pos_x\":\"pos\", \"pos_y\":\"pos from cap_wins\"})\n",
    "LTs = LTs.drop(columns=[\"team_name\", \"player_id\",\"pos from cap_wins\",'grades_pass_block','grades_run_block','non_spike_pass_block_percentage','pass_block_percent','pbe']) #might put back pos from cap\n",
    "LTs.drop_duplicates(subset=None, keep=\"first\", inplace=True)\n",
    "LTs.replace(np.nan,0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bdea9f",
   "metadata": {},
   "source": [
    "## LT Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdb7e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing test features\n",
    "LTfeats = ['player_game_count','grades_offense','snap_counts_pass_block','snap_counts_run_block','penalties','pressures_allowed','sacks_allowed','hits_allowed','hurries_allowed']\n",
    "#Assigning X (features/attributes)\n",
    "x = LTs[LTfeats]\n",
    "#Assigning Y (label/predicted val)\n",
    "y = LTs['Season Wins']\n",
    "\n",
    "\n",
    "#Split the data into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1000)\n",
    "\n",
    "#Standardizing the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_sc = scaler.transform(x_train)\n",
    "x_test_sc = scaler.transform(x_test)\n",
    "\n",
    "\n",
    "#Setting up Linear Regression Model\n",
    "linReg = LinearRegression()\n",
    "linReg.fit(x_train_sc, y_train)\n",
    "\n",
    "#Letting model make prediction\n",
    "y_test_pred = linReg.predict(x_test_sc)\n",
    "y_train_pred = linReg.predict(x_train_sc)\n",
    "\n",
    "\n",
    "#Checking MAE, MSE, and RMSE\n",
    "vMAE = (metrics.mean_absolute_error(y_test, y_test_pred))\n",
    "tMAE = (metrics.mean_absolute_error(y_train, y_train_pred))\n",
    "cMAE = np.mean(-cross_val_score(linReg, x, y, cv=5, scoring=\"neg_mean_absolute_error\"))\n",
    "\n",
    "\n",
    "vMSE = (metrics.mean_squared_error(y_test, y_test_pred))\n",
    "tMSE = (metrics.mean_squared_error(y_train, y_train_pred))\n",
    "cross_val_mse = np.mean(-cross_val_score(linReg, x, y, cv=5, scoring=\"neg_mean_squared_error\"))\n",
    "\n",
    "vRMSE = math.sqrt(vMSE)\n",
    "tRMSE = math.sqrt(tMSE)\n",
    "cRMSE = math.sqrt(cross_val_mse)\n",
    "\n",
    "print(\"Testing MAE:\")\n",
    "print(tMAE)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"5-Fold Cross Validation MAE:\")\n",
    "print(cMAE)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Testing RMSE:\")\n",
    "print(tRMSE)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"5-Fold Cross Validation RMSE:\")\n",
    "print(cRMSE)\n",
    "LT_vMAE = cMAE\n",
    "LT_vRMSE = cRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4877ee1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LTdrop = ['cap_hit','player_game_count', 'block_percent',\n",
    "       'declined_penalties', 'franchise_id', 'grades_offense', 'hits_allowed',\n",
    "       'hurries_allowed', 'non_spike_pass_block', 'penalties',\n",
    "       'pressures_allowed', 'sacks_allowed', 'snap_counts_block',\n",
    "       'snap_counts_ce', 'snap_counts_lg', 'snap_counts_lt',\n",
    "       'snap_counts_offense', 'snap_counts_pass_block',\n",
    "       'snap_counts_pass_play', 'snap_counts_rg', 'snap_counts_rt',\n",
    "       'snap_counts_run_block', 'snap_counts_te']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1321869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LT_Train = LTs.loc[y_train.index]\n",
    "LT_Train = LT_Train.drop(columns = LTdrop)\n",
    "LT_Train[\"Predicted Wins\"] = y_train_pred\n",
    "#____________________________________________________________________________________________________________________________\n",
    "LT_Test = LTs.loc[y_test.index]\n",
    "LT_Test = LT_Test.drop(columns = LTdrop)\n",
    "LT_Test[\"Predicted Wins\"] = y_test_pred\n",
    "\n",
    "\n",
    "predictedLTs = pd.concat([LT_Train, LT_Test])\n",
    "predictedLTs['pos']='LT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea567273",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictedLTs_top7 = top7[top7['pos']=='LT']\n",
    "predictedLTs_top7 = predictedLTs_top7.merge(predictedLTs, on=[\"Player\",'pos', \"season\", \"team\",'cap_percent'], how='left')\n",
    "predictedLTs_top7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f968ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedLTs_top7.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d926ee36",
   "metadata": {},
   "source": [
    "## Guards DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b486921d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Gs  = stats_guards[['season',\"player\",'position','team_name','player_game_count','grades_offense','snap_counts_pass_block','snap_counts_run_block','penalties','pressures_allowed','sacks_allowed','grades_pass_block','grades_run_block','hits_allowed','hurries_allowed']].copy()\n",
    "Gs = Gs.rename(columns={\"player\":\"Player\", \"position\":\"pos\"})\n",
    "Gs = Gs[Gs['pos'] == \"G\"]\n",
    "Gs = cap_wins.merge(Gs, on=[\"Player\", \"season\", \"pos\"], how='inner')\n",
    "Gs = Gs.drop(columns=[\"team_name\"])\n",
    "Gs.drop_duplicates(subset=None, keep=\"first\", inplace=True)\n",
    "Gs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e3b1e6",
   "metadata": {},
   "source": [
    "## Guards Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b131853d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing test features\n",
    "Gfeats = ['player_game_count','grades_offense','snap_counts_pass_block','snap_counts_run_block','penalties','pressures_allowed','sacks_allowed','hits_allowed','hurries_allowed']\n",
    "#Assigning X (features/attributes)\n",
    "x = Gs[Gfeats]\n",
    "#Assigning Y (label/predicted val)\n",
    "y = Gs['Season Wins']\n",
    "\n",
    "\n",
    "#Split the data into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1000)\n",
    "\n",
    "#Standardizing the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_sc = scaler.transform(x_train)\n",
    "x_test_sc = scaler.transform(x_test)\n",
    "\n",
    "\n",
    "#Setting up Linear Regression Model\n",
    "linReg = LinearRegression()\n",
    "linReg.fit(x_train_sc, y_train)\n",
    "\n",
    "#Letting model make prediction\n",
    "y_test_pred = linReg.predict(x_test_sc)\n",
    "y_train_pred = linReg.predict(x_train_sc)\n",
    "\n",
    "\n",
    "#Checking MAE, MSE, and RMSE\n",
    "vMAE = (metrics.mean_absolute_error(y_test, y_test_pred))\n",
    "tMAE = (metrics.mean_absolute_error(y_train, y_train_pred))\n",
    "cMAE = np.mean(-cross_val_score(linReg, x, y, cv=5, scoring=\"neg_mean_absolute_error\"))\n",
    "\n",
    "\n",
    "vMSE = (metrics.mean_squared_error(y_test, y_test_pred))\n",
    "tMSE = (metrics.mean_squared_error(y_train, y_train_pred))\n",
    "cross_val_mse = np.mean(-cross_val_score(linReg, x, y, cv=5, scoring=\"neg_mean_squared_error\"))\n",
    "\n",
    "vRMSE = math.sqrt(vMSE)\n",
    "tRMSE = math.sqrt(tMSE)\n",
    "cRMSE = math.sqrt(cross_val_mse)\n",
    "\n",
    "print(\"Testing MAE:\")\n",
    "print(tMAE)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"5-Fold Cross Validation MAE:\")\n",
    "print(cMAE)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Testing RMSE:\")\n",
    "print(tRMSE)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"5-Fold Cross Validation RMSE:\")\n",
    "print(cRMSE)\n",
    "G_vMAE = cMAE\n",
    "G_vRMSE = cRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b662a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gdrop = ['player_game_count',\"cap_hit\",'grades_offense','snap_counts_pass_block','snap_counts_run_block','penalties','pressures_allowed','sacks_allowed','grades_pass_block','grades_run_block','hits_allowed','hurries_allowed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8244816b",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_Train = Gs.loc[y_train.index]\n",
    "G_Train = G_Train.drop(columns = Gdrop)\n",
    "G_Train[\"Predicted Wins\"] = y_train_pred\n",
    "#____________________________________________________________________________________________________________________________\n",
    "G_Test = Gs.loc[y_test.index]\n",
    "G_Test = G_Test.drop(columns = Gdrop)\n",
    "G_Test[\"Predicted Wins\"] = y_test_pred\n",
    "\n",
    "\n",
    "predictedGs = pd.concat([G_Train, G_Test])\n",
    "predictedGs['pos']='G'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b974cbe6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictedGs_top7 = top7[top7['pos']=='G']\n",
    "predictedGs_top7 = predictedGs_top7.merge(predictedGs, on=[\"Player\",\"pos\", \"season\", \"team\",'cap_percent'], how='left')\n",
    "predictedGs_top7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e249ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedGs_top7.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bceb60",
   "metadata": {},
   "source": [
    "# Model 1 Findings and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07ffb93",
   "metadata": {},
   "source": [
    "### Grouped Bar Chart - Model 1:           (5-Fold Cross Validation Errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302707e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['QB', 'WR', 'G', 'LT', 'OLB/DE', \"DT\", \"CB\"]\n",
    "validation_MAEs = [QB_vMAE, WR_vMAE, G_vMAE, LT_vMAE, OLB_DE_vMAE, DT_vMAE, CB_vMAE]\n",
    "validation_RMSEs = [QB_vRMSE, WR_vRMSE, G_vRMSE, LT_vRMSE, OLB_DE_vRMSE, DT_vRMSE, CB_vRMSE]\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.25  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, validation_MAEs, width, label='5-Fold Cross Validation MAE', color=\"green\")\n",
    "rects2 = ax.bar(x + width/2, validation_RMSEs, width, label='5-Fold Cross Validation RMSE', color='red')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('MAE/RMSE Values')\n",
    "ax.set_title(\"Measure of Errors for Each Position's Linear Regression Model\")\n",
    "ax.set_xlabel('Positions')\n",
    "ax.set_xticks(x, labels)\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "plt.legend( loc='upper right', bbox_to_anchor=(-0.1, 1.), fontsize=10)\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890c2785",
   "metadata": {},
   "source": [
    "The visualization above depicts the 5-fold cross validation errors from every linear regression model we ran on each position. The measurements of error we are using are Mean Absolute Error (MAE), and Root Mean Squared Error (RMSE). Every position's prediction is right around 2-3 games. We are pleased with this outcome because the linear regression model has limitations. \n",
    "\n",
    "The site https://iq.opengenus.org/advantages-and-disadvantages-of-linear-regression/ has a good explanation of advantages and disadvantages of linear regressions. For example, the site states: \"Since linear regression assumes a linear relationship between the input and output variables, it fails to fit complex datasets properly. In most real life scenarios the relationship between the variables of the dataset isn't linear and hence a straight line doesn't fit the data properly.\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538ce2eb",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6a15fd",
   "metadata": {},
   "source": [
    "Model 2, Version 1:\n",
    "\n",
    "This is where we take the predicted wins value for each highest paid position of each team, from seasons 2014-2020. We plug these values into a DataFrame, this one being called 'm1_v1'. Due to inconsistencies while merging the datasets, there were lots of NaN values. So, we dropped any teams from this DataFrame that had as small as only 1 NaN player. We chose to do this because we wanted the data for m1_v1 to be strictly derived from our datasets. The independent values were the individual players' win predictions, and the dependent/predicted value was the team's win value for the season.\n",
    "\n",
    "Model 2, Version 2:\n",
    "\n",
    "While version 1 worked out to be somewhat accurate, since we dropped so many observations due to the NaN values, we decided that we'd run a similar model, imputing values for the missing data. This turned out to be Model 2, Version 2, in DataFrame 'm2_v2'. We imputed the data based on two conditions: If there were other instances of a player, where we could obtain other predicted win values they have for other seasons, we took the mean of those values. Otherwise, we'd set their predicted win value as the average of all predicted win values for that given position. Once we did this and updated the DataFrame, m2_v2 was ready to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc18a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making index labels for model 2. Each observation/row will be a team for each season\n",
    "\n",
    "season_years = [2014, 2015, 2016, 2017, 2018, 2019, 2020]\n",
    "season_yrs = [14, 15, 16, 17, 18, 19, 20]\n",
    "m2_teams = []\n",
    "\n",
    "\n",
    "for year in range(len(season_years)):\n",
    "    \n",
    "    lst = \"team_list\" + str(season_yrs[year])\n",
    "    \n",
    "    for team in globals()[lst]:\n",
    "        \n",
    "        string = str(season_years[year]) + \" \" + str(team)\n",
    "        m2_teams.append(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f95e820",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2Wins = []\n",
    "\n",
    "season_years = [2014, 2015, 2016, 2017, 2018, 2019, 2020]\n",
    "for year in range(len(season_years)):\n",
    "    df = cap_wins[cap_wins[\"season\"]==season_years[year]]\n",
    "    df = df.drop_duplicates(subset=[\"team\"])\n",
    "    win_series = df[\"Season Wins\"]\n",
    "    win_list = win_series.tolist()\n",
    "    for i in range(len(win_list)):\n",
    "        m2Wins.append(win_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336e14b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = pd.DataFrame(index=m2_teams, columns=([important_pos]))\n",
    "m2[\"Season Wins\"] = m2Wins\n",
    "for i in range(len(important_pos)):\n",
    "    m2[important_pos[i]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc16d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_list = [predictedQBs_top7, predictedWRs_top7, predictedOLBDEs_top7, predictedGs_top7, predictedLTs_top7, predictedCBs_top7,predictedDTs_top7]\n",
    "preds_posName = [\"QB\", \"WR\", \"OLB/DE\", \"G\", \"LT\",\"CB\",\"DT\"]\n",
    "\n",
    "for pred in range(len(preds_list)):\n",
    "    predictedXs_top7 = preds_list[pred]\n",
    "    pos = preds_posName[pred]\n",
    "    \n",
    "    for i in range(len(m2)):\n",
    "        year = m2.index[i][0:4]\n",
    "        year = int(year)\n",
    "        team = m2.index[i][5:]\n",
    "        obs = m2.index[i]\n",
    "        \n",
    "        for XB in range(len(predictedXs_top7)):\n",
    "            \n",
    "            if (predictedXs_top7.loc[XB][\"season\"]==year):\n",
    "                if (predictedXs_top7.loc[XB][\"team\"]==team):\n",
    "                    \n",
    "                    m2.at[obs, pos] = predictedXs_top7.iloc[XB][\"Predicted Wins\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54a2472",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd89b0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedXs_top7_list = [predictedQBs_top7, predictedWRs_top7, predictedGs_top7, predictedLTs_top7, predictedCBs_top7, predictedOLBDEs_top7, predictedDTs_top7]\n",
    "top7_posList = [\"QB\", \"WR\", \"G\", \"LT\", \"CB\", \"OLB/DE\", \"DT\"]\n",
    "for i in range(len(predictedXs_top7_list)):\n",
    "    num = predictedXs_top7_list[i].isna().sum()[\"Predicted Wins\"]\n",
    "    print(\"For \"+ top7_posList[i] +\" there are \"+str(num)+\" NaN players.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33750b14",
   "metadata": {},
   "source": [
    "Because of these unfortunate numbers, we will run two versions of Model 2:\n",
    "    \n",
    "1. A version where we drop any team with a NaN player. This will cause the amount of observations we have to be extremely low, however we will be confident that it is all real data, and none of it will be imputed.\n",
    "        \n",
    "        \n",
    "2. The next version will contain all teams, but with imputed data for the missing players. For our plan to impute the data, first we will check if there are any other instances of a missing player. If there are, we will average their win predictions from other seasons. In the case that there are no other instances of that player, we will take the average of all of that position's \"Predicted Wins\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4447fd70",
   "metadata": {},
   "source": [
    "# Model 2 - Version 1 (Dropping NaN Values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cde88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_v1 = m2.dropna()\n",
    "m2_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49343768",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing test features\n",
    "m2feats = ['QB', 'WR', 'G', 'LT', 'CB', 'OLB/DE', 'DT']\n",
    "#Assigning X (features/attributes)\n",
    "x = m2_v1[m2feats]\n",
    "#Assigning Y (label/predicted val)\n",
    "y = m2_v1['Season Wins']\n",
    "\n",
    "\n",
    "#Split the data into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5, random_state=28)\n",
    "\n",
    "#Standardizing the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_sc = scaler.transform(x_train)\n",
    "x_test_sc = scaler.transform(x_test)\n",
    "\n",
    "\n",
    "#Setting up Linear Regression Model\n",
    "linReg = LinearRegression()\n",
    "linReg.fit(x_train_sc, y_train)\n",
    "\n",
    "#Letting model make prediction\n",
    "y_test_pred = linReg.predict(x_test_sc)\n",
    "y_train_pred = linReg.predict(x_train_sc)\n",
    "\n",
    "\n",
    "#Checking MAE, MSE, and RMSE\n",
    "vMAE = (metrics.mean_absolute_error(y_test, y_test_pred))\n",
    "tMAE = (metrics.mean_absolute_error(y_train, y_train_pred))\n",
    "cMAE = np.mean(-cross_val_score(linReg, x, y, cv=5, scoring=\"neg_mean_absolute_error\"))\n",
    "\n",
    "\n",
    "vMSE = (metrics.mean_squared_error(y_test, y_test_pred))\n",
    "tMSE = (metrics.mean_squared_error(y_train, y_train_pred))\n",
    "cross_val_mse = np.mean(-cross_val_score(linReg, x, y, cv=5, scoring=\"neg_mean_squared_error\"))\n",
    "\n",
    "vRMSE = math.sqrt(vMSE)\n",
    "tRMSE = math.sqrt(tMSE)\n",
    "cRMSE = math.sqrt(cross_val_mse)\n",
    "\n",
    "print(\"Testing MAE:\")\n",
    "print(tMAE)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"5-Fold Cross Validation MAE:\")\n",
    "print(cMAE)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Testing RMSE:\")\n",
    "print(tRMSE)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"5-Fold Cross Validation RMSE:\")\n",
    "print(cRMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cb5eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_v1_Train = m2_v1.loc[y_train.index]\n",
    "m2_v1_Train[\"Predicted Wins\"] = y_train_pred\n",
    "#____________________________________________________________________________________________________________________________\n",
    "m2_v1_Test = m2_v1.loc[y_test.index]\n",
    "m2_v1_Test[\"Predicted Wins\"] = y_test_pred\n",
    "\n",
    "\n",
    "m2_v1_outcome = pd.concat([m2_v1_Test, m2_v1_Train])\n",
    "m2_v1_outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ec1851",
   "metadata": {},
   "source": [
    "# Model 2 - Version 2 (Imputing Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a240ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedXs_top7_list = [predictedQBs_top7, predictedWRs_top7, predictedGs_top7, predictedLTs_top7, predictedCBs_top7, predictedOLBDEs_top7, predictedDTs_top7]\n",
    "missingX = []\n",
    "top7_posList = [\"QB\", \"WR\", \"G\", \"LT\", \"CB\", \"OLB_DE\", \"DT\"]\n",
    "\n",
    "for i in range(len(top7_posList)):\n",
    "    \n",
    "    df = predictedXs_top7_list[i]\n",
    "    \n",
    "    missingStr = \"missing\" + top7_posList[i]\n",
    "    globals()[missingStr] = df[df['Predicted Wins'].isna()]\n",
    "    missingX.append(globals()[missingStr])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561c1a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedXs_top7_list = [predictedQBs_top7, predictedWRs_top7, predictedGs_top7, predictedLTs_top7, predictedCBs_top7, predictedOLBDEs_top7, predictedDTs_top7]\n",
    "\n",
    "for x in range(len(missingX)):\n",
    "    missingXB = missingX[x]\n",
    "    predictedXs_top7 = predictedXs_top7_list[x]\n",
    "\n",
    "\n",
    "    for i in range(len(missingXB)):\n",
    "        player = missingXB.iloc[i][\"Player\"]\n",
    "        team = missingXB.iloc[i][\"team\"]\n",
    "        season = missingXB.iloc[i][\"season\"]\n",
    "        mean_pred = predictedXs_top7.dropna()[\"Predicted Wins\"].mean()\n",
    "    \n",
    "    \n",
    "        df = predictedXs_top7[predictedXs_top7['Player']==player]\n",
    "        df = df.dropna()\n",
    "        dfLen = len(df)\n",
    "\n",
    "        idx = missingXB.index[i]\n",
    "    \n",
    "    #If there are other instances of a player, average their predicted wins\n",
    "        if dfLen > 1:\n",
    "            season_wins_list = []\n",
    "            predicted_wins_list = []\n",
    "            for x in range(dfLen):\n",
    "                pred_win = df.iloc[x][\"Predicted Wins\"]\n",
    "                seas_win = df.iloc[x][\"Season Wins\"]\n",
    "                if pred_win > 0:\n",
    "                    predicted_wins_list.append(pred_win)\n",
    "                if seas_win > 0:\n",
    "                    season_wins_list.append(seas_win)\n",
    "            \n",
    "            new_seas = sum(season_wins_list)/len(season_wins_list)\n",
    "#             if len(predicted_wins_list) >= 1:\n",
    "            new_pred = sum(predicted_wins_list)/len(predicted_wins_list)\n",
    "            \n",
    "            missingXB.at[missingXB.index[i], \"Predicted Wins\"] = new_pred\n",
    "            missingXB.at[missingXB.index[i], \"Season Wins\"] = new_seas\n",
    "                \n",
    "        \n",
    "        else:\n",
    "    #Assign the average of all predicted values for the position to their predicted value\n",
    "            missingXB.at[missingXB.index[i], \"Predicted Wins\"] = mean_pred\n",
    "\n",
    "    #Updating row in predictedQBs_top7\n",
    "        (predictedXs_top7.iloc[idx]) = (missingXB.loc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee728e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_list = [predictedQBs_top7, predictedWRs_top7, predictedOLBDEs_top7, predictedGs_top7, predictedLTs_top7, predictedCBs_top7,predictedDTs_top7]\n",
    "preds_posName = [\"QB\", \"WR\", \"OLB/DE\", \"G\", \"LT\",\"CB\",\"DT\"]\n",
    "\n",
    "for pred in range(len(preds_list)):\n",
    "    predictedXs_top7 = preds_list[pred]\n",
    "    pos = preds_posName[pred]\n",
    "    \n",
    "    for i in range(len(m2)):\n",
    "        year = m2.index[i][0:4]\n",
    "        year = int(year)\n",
    "        team = m2.index[i][5:]\n",
    "        obs = m2.index[i]\n",
    "        \n",
    "        for XB in range(len(predictedXs_top7)):\n",
    "            \n",
    "            if (predictedXs_top7.loc[XB][\"season\"]==year):\n",
    "                if (predictedXs_top7.loc[XB][\"team\"]==team):\n",
    "                    \n",
    "                    m2.at[obs, pos] = predictedXs_top7.iloc[XB][\"Predicted Wins\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5eedd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_v2 = m2\n",
    "m2_v2 = m2_v2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4d5dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing test features\n",
    "m2feats = ['QB', 'WR', 'G', 'LT', 'CB', 'OLB/DE', 'DT']\n",
    "#Assigning X (features/attributes)\n",
    "x = m2_v2[m2feats]\n",
    "#Assigning Y (label/predicted val)\n",
    "y = m2_v2['Season Wins']\n",
    "\n",
    "\n",
    "#Split the data into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5, random_state=28)\n",
    "\n",
    "#Standardizing the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_sc = scaler.transform(x_train)\n",
    "x_test_sc = scaler.transform(x_test)\n",
    "\n",
    "\n",
    "#Setting up Linear Regression Model\n",
    "linReg = LinearRegression()\n",
    "linReg.fit(x_train_sc, y_train)\n",
    "\n",
    "#Letting model make prediction\n",
    "y_test_pred = linReg.predict(x_test_sc)\n",
    "y_train_pred = linReg.predict(x_train_sc)\n",
    "\n",
    "\n",
    "#Checking MAE, MSE, and RMSE\n",
    "vMAE = (metrics.mean_absolute_error(y_test, y_test_pred))\n",
    "tMAE = (metrics.mean_absolute_error(y_train, y_train_pred))\n",
    "cMAE = np.mean(-cross_val_score(linReg, x, y, cv=5, scoring=\"neg_mean_absolute_error\"))\n",
    "\n",
    "\n",
    "vMSE = (metrics.mean_squared_error(y_test, y_test_pred))\n",
    "tMSE = (metrics.mean_squared_error(y_train, y_train_pred))\n",
    "cross_val_mse = np.mean(-cross_val_score(linReg, x, y, cv=5, scoring=\"neg_mean_squared_error\"))\n",
    "\n",
    "vRMSE = math.sqrt(vMSE)\n",
    "tRMSE = math.sqrt(tMSE)\n",
    "cRMSE = math.sqrt(cross_val_mse)\n",
    "\n",
    "print(\"Testing MAE:\")\n",
    "print(tMAE)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"5-Fold Cross Validation MAE:\")\n",
    "print(cMAE)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Testing RMSE:\")\n",
    "print(tRMSE)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"5-Fold Cross Validation RMSE:\")\n",
    "print(cRMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d464b34b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m2_v2_Train = m2_v2.loc[y_train.index]\n",
    "m2_v2_Train[\"Predicted Wins\"] = y_train_pred\n",
    "#____________________________________________________________________________________________________________________________\n",
    "m2_v2_Test = m2_v2.loc[y_test.index]\n",
    "m2_v2_Test[\"Predicted Wins\"] = y_test_pred\n",
    "\n",
    "\n",
    "m2_v2_outcome = pd.concat([m2_v2_Test, m2_v2_Train])\n",
    "m2_v2_outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b1854d",
   "metadata": {},
   "source": [
    "# Model 2 Results and Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42836f1a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "act_vs_pred = pd.DataFrame()\n",
    "p = m2_v2_outcome[\"Predicted Wins\"].sort_index().squeeze()\n",
    "a = m2_v2_outcome[\"Season Wins\"].sort_index().squeeze()\n",
    "act_vs_pred[\"Season Wins\"] = a\n",
    "act_vs_pred[\"Predicted Wins\"] = p\n",
    "act_vs_pred.iloc[0:32].plot.bar(width=.5, figsize=(12,5), ylabel=\"Win Value\", title=\"NFL 2014 Predicted vs. Actual Wins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423cfa77",
   "metadata": {},
   "source": [
    "The above model is a grouped bar chart showing predicted versus actual wins for the 32 teams in the 2014 NFL season. As the legend in the top right corner specifies, the blue bars are a team's actual wins, and the orange bars are a team's predicted wins from Model 2, Version 2. As one could see, some values were closely predicted, and others not so much. With a 5-Fold CV MAE of 1.7 and a 5-Fold CV RMSE of 2.1, the error visualized in this chart makes more sense. We are pleased with these results because we are using a linear regression model which has limitations (like we previously mentioned)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86810337",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = pd.concat([pd.DataFrame(m2feats),pd.DataFrame(np.transpose(linReg.coef_))], axis = 1)\n",
    "coefficients = coefficients.set_index([m2feats])\n",
    "coefficients = np.transpose(coefficients)\n",
    "coefficients.iloc[0] = coefficients.iloc[1]\n",
    "coefficients = coefficients.drop_duplicates()\n",
    "coefficients = np.transpose(coefficients)\n",
    "coefficients = coefficients.rename(columns={0: \"Beta Coefficients\"})\n",
    "coefficients.plot.bar(title=\"Each Position's Beta Coefficient Value\", xlabel=\"Position\", ylabel=\"Coefficient Value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748de072",
   "metadata": {},
   "source": [
    "The graph above shows us the beta coefficients for each position in Model 2, Version 2. The higher the beta coefficient, the more \"importance\" the model places on that specific position. We see that the model placed high importance on QB and LT. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14c2811",
   "metadata": {},
   "source": [
    "<h1><center>5. Conclusion<h1><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae958e4",
   "metadata": {},
   "source": [
    "We were relatively successful in predicting NFL teams’ success with a limited number of positions. The linear regression model was able to predict, on average, within 2-3 wins for any given NFL Franchise. Our findings suggest that the importance of each position in the NFL is weighted quite differently when predicting team wins. For instance, when looking at the graph displaying the positions' beta coefficients, you see that the top 2 positions are offensive positions. Many people reference the importance of scoring points in \"modern football\", and our findings support this claim. As Dan Marino once said, \"There is no defense against a perfect pass. I can throw a perfect pass.” \n",
    "\n",
    "However, a large portion of one player's success comes from those around him. For instance, a QB needs a WR to get open and the WR needs the QB to throw a good pass. Our goal was not to evaluate \"team\" stats, but to try to separate positions and use only those deemed significant. We believe we accomplished this and have further ideas for improvement. Since our data is limited and contains NaN values, an XGBoost model would most likely have predicted with higher success. \n",
    "\n",
    "Nevertheless, while this project is far from perfect, we are satisfied with what we've created, and can proudly display a working analysis with many interesting aspects. \n",
    "\n",
    "This is our final product for our NFL Analysis, and thank you for reading."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9779729",
   "metadata": {},
   "source": [
    "<h1><center>6. Lessons Learned<h1><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b74251",
   "metadata": {},
   "source": [
    "### If only we could go back in time\n",
    "\n",
    "1) Using data from two different sources can create nightmare scenarios. \n",
    "\n",
    "- We spent much of our time trying to figure out ways to link data properly so that most of the data would stay. This was incredibly painful and time consuming. However, we found this time was beneficial and applicable to real world scenarios.\n",
    "\n",
    "2) Save and rerun your notebook multiple times.\n",
    "\n",
    "- Funky things can happen. When you are working variables can change and functions can be run in a non-linear fashion after you have been working for a while. This can cause issues later when you open your notebook the next day, and it says \"XYZ Function is not defined.\"\n",
    "\n",
    "3) Planning is essential.\n",
    "\n",
    "- The hardest part was choosing what we wanted to examine. We had endless options of choices: which data sources to use? Which stats to look at? What time period? etc. We had to make endless judgment calls and constantly narrow down our focus to accomplish our goal of predicting an NFL team's win count. When we first started our project was called \"Factors influencing NFL Games\" - Looking back now, this sounds like a train wreck because the word \"factors\" is so vague. Narrow your focus, choose well, clean data and your life is much better.\n",
    "\n",
    "4) Always focus on the question at hand.\n",
    "\n",
    "- You can get lost in the sauce. When you are performing an action, function, merge, model, etc, ask yourself why you are doing it. We learned this the hard way and spent a good chunk of our time creating useless functions or graphs. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
